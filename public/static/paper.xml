<paperlist>
	<paper>
		<ID>10</ID>
		<title>Recurring and Novel Class Detection in Concept-Drifting Data Streams using Class-Based Ensemble</title>
		<authors>Mohammad Islam (BUET)</authors>
		<abstract>Over the recent years concept-evolution has received a lot of attention because of its importance in the context of mining data streams. Mining data stream has become an important task due to its wide range of applications such as network intrusion detection, credit card fraud protection, identifying trends in the social networks etc. Concept-evolution means introduction of novel class in the data stream. Many recent works address this phenomenon. In addition, a class may appear in the stream, disappears for a while and then reemerges. This scenario is known as recurring classes and remained unaddressed in most of the cases. As a result, generally where a novel class detection system is present, any recurring class is falsely detected as novel class. This results in unnecessary waste of human and computational resources. In this paper, we have proposed a class-based ensemble of classification model addressing the issues of recurring and novel class in the presence of concept drift and noise. Our approach has shown impressive performance compared to the state-of-art methods in the literature.</abstract>
	</paper>
	<paper>
		<ID>11</ID>
		<title>Brownian Bridge Model for High Resolution Location Predictions</title>
		<authors>Miao Lin (Nanyang Technological University),Wen-Jing Hsu (Nanyang Technological University)</authors>
		<abstract>Given a person's current and historical traces, a useful yet challenging task is to predict the future locations at high spatial-temporal resolution. In this study, we propose a Brownian Bridge model to predict a person's future location by using the individual's historical traces that exhibit similarity with the current trace. The similarity of the traces with the current trace is evaluated based on the notion of edit distance. The predicted location at the future point in time is a weighted result obtained from a modified Brownian Bridge model that incorporates linear extrapolation. Both Brownian Bridge and linear extrapolation aim to capture aspects of the individual's mobility behaviors. Compared to using either historical records or linear extrapolation method alone, the proposed location prediction method shows lower mean prediction error in predicting locations at different time horizons.</abstract>
	</paper>
	<paper>
		<ID>12</ID>
		<title>Domain Transfer via Multiple Sources Regularization</title>
		<authors>Shaofeng Hu (Sun Yat-sen University),Jiangtao Ren (Sun Yat-sen University),Changshui Zhang (Tsinghua University),Chaogui Zhang (Sun Yat-sen University)</authors>
		<abstract>The common assumption that training and testing samples share the same distribution is often violated in practice. When this happens, traditional learning models may not generalize well. To solve this problem, domain adaptation and transfer learning try to employ training data from other related source domains. We propose a multiple sources regularization framework for this problem. The framework extends classification model with regularization by adding a special regularization term, which penalizes the target classifier far from the convex combination of source classifiers. Then this framework guarantees the target classifier minimizes the empirical risk in target domain and the distance from the convex combination of source classifier simultaneously. By the way, the weights of the convex combination of source classifiers are embedded into the learning model as parameters, and will be learned through optimization algorithm automatically, which means our framework can identify similar or related domains adaptively. We apply our framework to SVM classification model and develop an optimization algorithm to solve this problem in iterative manner. Empirical study demonstrates the proposed algorithm outperforms some state-of-art related algorithms on real-world datasets, such as text categorization and optical recognition.</abstract>
	</paper>
	<paper>
		<ID>18</ID>
		<title>Persistent Community Detection in Dynamic Social Networks</title>
		<authors>Siyuan Liu (CMU),Shuhui Wang (ICT, CAS),Ramayya Krishnan (CMU)</authors>
		<abstract>While community detection is an active area of research in social network analysis, little effort has been devoted to community detection using time-evolving social network data. We propose a novel algorithm, Persistent Community Detection (PCD), a time and degree-corrected blockmodel, to identify those communities that exhibit persistent behavior over time, for usage in such settings. Our motivation is to distinguish between steady-state network activity, and impermanent behavior such as cascades caused by a noteworthy event. The results of extensive empirical experiments on real-life big social networks data show that our algorithm performs much better than a set of baseline methods, including two alternative models and the state-of-the-art. </abstract>
	</paper>
	<paper>
		<ID>32</ID>
		<title>Fast Triangle Core Decomposition for Mining Large Graphs</title>
		<authors>Ryan Rossi (Purdue University)</authors>
		<abstract>Large triangle cores represent dense subgraphs for which each edge has at least $k-2$ triangles (same as cliques). This paper presents a fast algorithm for computing the triangle core decomposition on big graphs. The proposed triangle core algorithm adapts both the computations and representation based on the properties of the graph. In addition, we develop a fast edge-based parallel triangle counting algorithm, which lies at the heart of the triangle core decomposition. The proposed algorithm is orders of magnitude faster than the currently available approach. We also investigate and propose fast methods for two variants of the triangle core problem: computing only the top-k triangle cores fast and finding the maximum triangle core number of the graph. The experiments demonstrate the scalability and effectiveness of our approach on 150+ networks with up to 1.8 billion-edges. Further, we apply the proposed methods for graph mining tasks including finding dense subgraphs, temporal strong components, and maximum cliques.</abstract>
	</paper>
	<paper>
		<ID>34</ID>
		<title>A Graphical Model for Collective Behavior Learning Using Minority Games</title>
		<authors>Farhan Khawar (Beihang University),Zengchang Qin (Beihang University)</authors>
		<abstract>The Minority Game (MG) is a simple game theory model for the collective behavior of agents in an idealized situation where they compete for some finite resource. In this paper, we assume that collective behavior is determined by the aggregation of individual actions of agents. This causal relation between collective behavior and individual actions is investigated. A graphical model is proposed to model the generative process of collective behavior using a group of agents whose actions are modeled by minority games. In this model, we can infer the individual behavior of the agents by training on the global information, and then make predictions about the future collective behavior. The new proposed model is applied to real-world time series data prediction. Experimental results on a set of stock indexes from the Chinese market and foreign exchange (FX) rates show that the new proposed model can effectively capture the rises and falls of market and be significantly better than a random predictor. This framework also provides a new data mining paradigm for analyzing collective data by modeling micro-level actions of agents using game theory models.</abstract>
	</paper>
	<paper>
		<ID>36</ID>
		<title>An Iterative Fusion Approach to Graph-based Semi-supervised Learning from Multiple Views</title>
		<authors>Yang Wang (UNSW),Jian Pei (Simon Fraser University, Canana),Xuemin Lin (The University of New South Wales, Australia),Qing Zhang (Australia e-health research center),Wenjie Zhang ()</authors>
		<abstract>Often, a data object described by many features can be naturally decomposed into multiple “views”, where each view consists of a subset of features. For example, a video clip may have a video view and an audio view. Given a set of training data objects with multiple views, where some objects are labeled and the others are not, semi-supervised learning with graphs from multi-views tries to learn a classifier by treating each view as a similarity graph on all ob- jects, where edges are defined by the similarity on object pairs based on the view attributes. Labels and label relevance ranking scores of labeled objects can be propagated from labeled objects to unlabeled objects on the similarity graphs so that similar objects receive similar labels. The state-of-the-art, one-combo-fits-all methods linearly combine either the metrics or the label propagation results from multi-views and then build a model based on the combined results. However,  the similarities between various objects may be manifested differently by different views. In such situations, the one-combo-fits-all methods may not perform well. To tackle the problem, we develop an iterative Semi- Supervised Metric Fusion (SSMF) approach in this paper. SSMF fuses metrics and label propagation results from multi-views iteratively until the fused metric and label propagation results converge simultaneously. Views are weighted dynamically during the fusion process so that the adversary effect of irrelevant views, identified at each iteration of fusion process, can be reduced effectively. To evaluate the effectiveness of SSMF, we apply it on multi-view based and content based image retrieval and multi-view based multi-label image classification on real world data set, which demonstrates that our method outperforms the state-of-the-art methods.</abstract>
	</paper>
	<paper>
		<ID>42</ID>
		<title>Privacy Preserving Publication of Locations Based on Delaunay Triangulation</title>
		<authors>Jun Luo (Chinese Academy of Sciences),Jinfei Liu (Emory University),Li Xiong (Emory University)</authors>
		<abstract>The pervasive usage of LBS (Location Based Services) has caused serious risk of personal privacy. In order to preserve the privacy of locations, only the anonymized or perturbated data are published. At the same time, the data mining results for the perturbated data should keep as close as possible to the data mining results for the original data. In this paper, we propose a novel perturbation method such that the Delaunay triangulation of the perturbated data is the same as that of the original data. Theoretically, the Delaunay triangulation of point data set presents the neighborhood relationships of points. Many data mining algorithms strongly depend on the neighborhood relationships of points. Our method is proved to be effective and efficient by performing several popular data mining algorithms such as KNN, K-means, DBSCAN.</abstract>
	</paper>
	<paper>
		<ID>43</ID>
		<title>Finding Better Topics: Features, Priors and Constraints</title>
		<authors>Xiaona Wu (Soochow University),Jia Zeng (),Jianfeng Yan (),Xiaosheng Liu ()</authors>
		<abstract>Latent Dirichlet allocation (LDA) is one of popular paradigms for probabilistic topic modeling.In practice,users of LDA are usually faced with two problems.First,common and stop words tend to occupy all of the topics leading to bad topic interpretability. Second,there is little guidance on how to improve the low-dimensional topic-based features for a better clustering or classification performance.To find better topics,we re-examine LDA from three perspectives:continuous features, asymmetric Dirichlet priors and sparseness constraints,using variants of belief propagation (BP) inference algorithms.We show that continuous features can remove common and stop words from topics effectively. Asymmetric Dirichlet priors have substantial advantages over symmetric priors in document classification.Sparseness constraints also improve the document classification and clustering performance.</abstract>
	</paper>
	<paper>
		<ID>45</ID>
		<title>Determine optimal number of clusters with an elitist evolutionary approach</title>
		<authors>Lydia Boudjeloud-Assala (LITA - University Lorraine),Ta Minh Thuy (LITA University Lorraine)</authors>
		<abstract>This article proposes an elitist evolutionary approach to determine the optimal number of clusters for clustering data sets. The proposed method is based on the cluster number optimization and in the same time, finds the potential clusters seeds. This method can be used as an initialization of k-means algorithm or directly as a clustering algorithm without prior knowledge of the clusters number. In this approach, elitist population is composed of the individuals with potential clusters seeds. We introduce a new mutation strategy according to the neighborhood search and new evaluation criteria. This strategy allows us to find the global optimal solution or near-optimal solution for clustering tasks, precisely finding the optimal clusters seeds. The experimental results  show that our algorithm performs well on multi-class and large-size data sets.</abstract>
	</paper>
	<paper>
		<ID>46</ID>
		<title>Extensions to Quantile Regression Forests for Very High Dimensional Data</title>
		<authors>Nguyen Thanh Tung (Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, China),Joshua Zhexue Huang (SZU),Imran Khan (SIAT(UCAS)),Mark Junjie Li (SZU),Graham Williams ()</authors>
		<abstract>This paper describes new extensions to the state-of-the-art regression random forests Quantile Regression Forests (QRF) for applications to high dimensional data with thousands of features. We propose a new subspace sampling method that randomly samples a subset of features from two separate feature sets, one containing important features and the other one containing less important features. The two feature sets partition the input data based on the importance measures of features. The partition is generated by using feature permutation to produce raw importance feature scores first and then applying $p$-value assessment to separate important features from the less important ones. The new subspace sampling method enables to generate trees from bagged sample data with smaller regression errors. For point regression, we choose the prediction value of $Y$ from the range between two quantiles $Q_{0.05}$ and $Q_{0.95}$ instead of the conditional mean used in regression random forests. Our experiment results have shown that random forests with these extensions outperformed regression random forests and quantile regression forests in reduction of root mean square residuals.</abstract>
	</paper>
	<paper>
		<ID>50</ID>
		<title>Detecting and Analyzing Influenza Epidemics with Social Media in China</title>
		<authors>Fang Zhang (),Jun Luo (Chinese Academy of Sciences),chao Li (),Xin Wang (University of Calgary, Canada),Zhongying Zhao ()</authors>
		<abstract>In recent years, social media has become important and omnipresent for social network and information sharing. Researchers and scientists have begun to mine social media data to predict varieties of social, economic, health and entertainment related real-world phenomena. In this paper, we exhibit how social media data can be used to detect and analyze real-world phenomena with several data mining techniques. Specifically, we use posts from TencentWeibo to detect influenza and analyze influenza trends. We build a support vector machine (SVM) based classifier to classify influenza posts. In addition, we use  association rule mining to extract strongly associated features as additional features of posts to overcome the limitation of 140 words for posts. We also use sentimental analysis to classify the reposts without feature and uncommented reposts. The experimental results show that by combining those techniques, we can improve the precision and recall by at least ten percent.  Finally, we analyze the spatial and temporal patterns for positive influenza posts and tell when and where influenza epidemic is more likely to occur.</abstract>
	</paper>
	<paper>
		<ID>51</ID>
		<title>Deferentially Private Tagging Recommendation based on Topic Model</title>
		<authors>Tianqing Zhu (Deakin university),Gang Li (Deakin University),Wanlei Zhou (),Ping Xiong (),Cao Yuan ()</authors>
		<abstract>Tagging recommender system allows Internet users to annotate resources with personalized tags and provides users the freedom to obtain recommendations. However, It is usually confronted with serious privacy concerns, because adversaries may re-identify a user and her/his sensitive tags with only a little background information. This paper proposes a privacy preserving tagging release algorithm, PriTop, which is designed to protect users under the notion of differential privacy. The proposed Pri-Top algorithm includes three privacy preserving operations: Private Topic Model Generation structures the uncontrolled tags, Private Weight Perturbation adds Laplace noise into the weights to hide the numbers of tags; while Private Tag Selection finally finds the most suitable replacement tags for the original tags. We present extensive experimental results on four real world datasets and results suggest the proposed PriTop algorithm can successfully retain the utility of the datasets while preserving privacy.</abstract>
	</paper>
	<paper>
		<ID>62</ID>
		<title>Highly Scalable Attribute Selection for Averaged One-Dependence Estimators</title>
		<authors>Shenglei Chen (Nanjing Audit University),Ana Martinez (Faculty of Information Technology, Monash University),Geoffrey Webb (Faculty of Information Technology, Monash University)</authors>
		<abstract> Averaged One-Dependence Estimators (AODE) is a popular and effective approach to Bayesian learning. In this paper, a new attribute selection approach is proposed for AODE. It can search in a large model space, while it requires only a single extra pass through the training data, resulting in a computationally efficient two-pass learning algorithm.  The experimental results indicate that the new technique significantly reduces AODE's bias at the cost of a modest increase in training time. Its low bias and computational efficiency make it an attractive algorithm for learning from big data.</abstract>
	</paper>
	<paper>
		<ID>69</ID>
		<title>Positional Translation Language Model for Ad-hoc Information Retrieval</title>
		<authors>Xinhui Tu (WUST),Jing Luo (),Bo Li (),Tingting He (),Jinguang Gu ()</authors>
		<abstract>Most existing language modeling approaches are based on the term independence hypothesis. To go beyond this assumption, two main directions were investigated. The first one considers the use of the proximity features that capture the degree to which search terms appear close to each other in a document. Another one considers the use of semantic relationships between words. Previous studies have proven that these two types of information, including term proximity features and semantic relationships between words, are both useful to improve retrieval performance. Intuitionally, we can use them in combination to further improve retrieval performance. Based on this idea, this paper propose a positional translation language model to explicitly incorporate both of these two types of information under language modeling framework in a unified way. In the first step, we present a proximity-based method to estimate word-word translation probabilities. Then, we define a translation document model for each position of a document and use these document models to score the document. Experimental results on standard TREC collections show that the proposed model achieves significant improvements over the state-of-the-art models, including positional language model, and translation language models.</abstract>
	</paper>
	<paper>
		<ID>72</ID>
		<title>Constrained Least Squares Regression for Semi-Supervised Learning</title>
		<authors>Bo Liu (Beijing Jiaotong University),Liping Jing (Beijing Key Lab of Traffic Data Analysis and Mining, Beijing Jiaotong University),Jian Yu (Beijing Key Lab of Traffic Data Analysis and Mining, Beijing Jiaotong University),Jia Li (Beijing Key Lab of Traffic Data Analysis and Mining, Beijing Jiaotong University)</authors>
		<abstract>The core tasks of graph based semi-supervised learning (GSSL) are constructing a proper graph and selecting suitable supervisory information. The ideal graph is able to outline the intrinsic data structure, and the ideal supervisory information could represent the whole data. In this paper, we propose a new graph learning method, called constrained least squares regression (CLSR), which integrates the supervisory information into graph learning process.  To learn a more adaptive graph, regression coefficients and neighbor relations are combined in CLSR to capture the global and local data structures respectively.  Moreover, as byproduct of CLSR, a new strategy is presented to select the high-quality data points as labeled samples, which is practical in real applications. Experimental results on different real world datasets demonstrate the effectiveness of CLSR and the sample selection strategy.</abstract>
	</paper>
	<paper>
		<ID>73</ID>
		<title>Rare Category Detection on O(dN) Time Complexity</title>
		<authors>Zhenguang Liu (),Hao Huang (),Qinming He (),Kevin Chiew (),Lianhang Ma (Zhejiang University)</authors>
		<abstract>Rare category detection (RCD) aims at finding out at least one data example of each rare category in an unlabeled data set with the help of a labeling oracle to prove the existence of such a rare category. Various approaches have been proposed for RCD with quadratic or even cubic time complexity. In this paper, by using histogram density estimation and wavelet analysis, we propose FRED algorithm and its prior-free version iFRED algorithm for RCD, both of which achieve linear time complexity w.r.t. either the data set size N or the data dimension d. Theoretical analysis guarantees its effectiveness, and comprehensive experiments on both synthetic and real data sets verify the effectiveness and efficiency of our algorithms.</abstract>
	</paper>
	<paper>
		<ID>74</ID>
		<title>Net-Ray: Visualizing and Mining Web-Scale Graphs</title>
		<authors>U Kang (KAIST),Jay-Yoon Lee (CMU),Danai Koutra (CMU),Christos Faloutsos (CMU)</authors>
		<abstract>How can we visualize billion-scale graphs? How to spot outliers in such graphs quickly? Visualizing graphs is the most direct way of understanding them; however, billion-scale graphs are very difficult to visualize since the amount of information overflows the resolution of a typical screen.   In this paper we propose Net-Ray, an open-source package for visualization-based mining on billion-scale graphs. Net-Ray visualizes graphs using the spy plot (adjacency matrix patterns), distribution plot, and correlation plot which involve careful node ordering and scaling. In addition, Net-Ray efficiently summarizes scatter clusters of graphs in a way that finds outliers automatically, and makes it easy to interpret them visually. To the best of our knowledge, Net-Ray is the first work for visual mining on billion-scale graphs.  Extensive experiments show that Net-Ray handles very large graphs with billions of nodes and edges efficiently and effectively. Specifically, among the various datasets that we study, we visualize in multiple ways the YahooWeb graph which spans 1.4 billion webpages and 6.6 billion links, and the Twitter who-follows-whom graph, which consists of 62.5 million users and 1.8 billion edges. We report interesting clusters and outliers spotted and summarized by Net-Ray. </abstract>
	</paper>
	<paper>
		<ID>77</ID>
		<title>Influence Propagation: Patterns, Model and a Case Study</title>
		<authors>Yibin Lin (Carnegie Mellon University),Agha Ali Raza (Carnegie Mellon University),Jay-Yoon Lee (Carnegie Mellon University),Danai Koutra (CMU),Roni Rosenfeld (Carnegie Mellon University),Christos Faloutsos (CMU)</authors>
		<abstract>When a free, catchy application shows up, how quickly will people notify their friends about it? Will the enthusiasm drop exponentially with time, or oscillate? What other patterns emerge?  Here we answer these questions using data from the Polly telephone-based application, a large influence network of 72,000 people, with about 173,000 interactions, spanning 500MB of log data and 200 GB of audio data. We report surprising patterns, the most striking of which are: (a) the FIZZLE pattern, i.e., excitement about Polly shows a power-law decay over time with exponent of -1.2; (b) the RENDEZVOUS pattern, that obeys a power law (we explain RENDEZVOUS in the text); (c) the DISPERSION pattern, we find that the more a person uses Polly, the fewer friends he will use it with, but in a reciprocal fashion.  Finally, we also propose a generator of influence networks, which generate networks that mimic our discovered patterns.</abstract>
	</paper>
	<paper>
		<ID>78</ID>
		<title>Ranking Tweets with Local and Global Consistency Using Rich Features</title>
		<authors>Zhankun Huang (ICT),Shenghua Liu (),Pan Du (),Xue-Qi Cheng (ICT)</authors>
		<abstract>Ranking tweets is more challenging in Microblog search because of content sparseness and lack of context. Traditional ranking methods essentially using Euclidean distance are limited to local structure. Manifold structure helps to rank with local and global consistency. However such structure is empirically built on content similarity in an unsupervised way, suffering from sparseness while being adopted in tweet ranking. In this paper, we explore rich features to alleviate content sparseness problem, where time locality feature is proposed to consider context dependency. We then propose a supervised learning model that aggregates rich features to construct manifold structure. A learning algorithm is then designed for solving the model by minimizing the loss of labeled queries. At last we conduct a series of experiments to demonstrate the performance on 109 labeled queries from TREC Microblogging. Compared with the well-known baselines and empirical manifold structure, our algorithm achieves consistent improvements on the metrics.</abstract>
	</paper>
	<paper>
		<ID>80</ID>
		<title>A Selectively Re-train Approach Based on Clustering To Classify Concept-drifting Data Streams with Skewed Distribution</title>
		<authors>Dandan Zhang (Beijing Jiaotong University),Shen Hong (),Tian Hui (),Yidong Li (Beijing Jiaotong Univeristy, China),Jun Wu (Beijing Jiaotong University),Yingpeng Sang ()</authors>
		<abstract>  Classification is an important and practical tool which uses a model built on historical data to predict class labels for new arrival data. In the last few years, there have been many interesting studies on classification in data streams. However, most such studies assume that those data streams are relatively balanced and stable. Actually, skewed data streams (e.g., few positive but lots of negatives) are very important and typical, which appear in many real world applications. Concept drifts and skewed distributions, two common properties of data streams, make the task of learning in streams particularly difficult and  the traditional data mining algorithms no longer work. In this paper, we propose a method (Selectively Re-train Approach Based on Clustering) which can deal with concept-drifting and skewed distribution simultaneously. We evaluate our algorithm on both synthetic and real data sets simulating skewed data streams. Empirical results show the proposed method yields  better performance than the previous work.</abstract>
	</paper>
	<paper>
		<ID>82</ID>
		<title>Gaussian Processes Autoencoder for Dimensionality Reduction</title>
		<authors>Xinwei Jiang (China University of Geosciences),Junbin Gao (Charles Sturt University, Australia),Xia Hong (University of Reading),Zhihua Cai (China University of Geosciences)</authors>
		<abstract>Learning low dimensional manifold from highly nonlinear data of high dimensionality has become increasingly important for discovering intrinsic representation that can be utilized for data visualization and preprocessing. The autoencoder is a powerful dimensionality reduction technique based on minimizing reconstruction error, and it has regained popularity because it has been efficiently used for greedy pre-raining of deep neural networks. Compared to Neural Network (NN), the superiority of Gaussian Process (GP) has been shown in model inference, optimization and performance. GP has been successfully applied in nonlinear Dimensionality Reduction (DR) algorithms, such as Gaussian Process Latent Variable Model (GPLVM). In this paper we propose the Gaussian Processes Autoencoder Model (GPAM) for dimensionality reduction by extending the classic NN based autoencoder to GP based autoencoder. More interestingly, the novel model can also be viewed as back constrained GPLVM (BC-GPLVM) where the back constraint smooth function is represented by a GP. Experiments verify the performance of the newly proposed model.</abstract>
	</paper>
	<paper>
		<ID>85</ID>
		<title>NLPMM: a Next Location Predictor with Markov Modeling</title>
		<authors>Meng Chen (ShanDong University),Yang Liu (Shandong University),Xiaohui Yu (Shandong University)</authors>
		<abstract>In this paper, we solve the problem of predicting the next locations of the moving objects with a historical dataset of trajectories. We present a Next Location Predictor with Markov Modeling (NLPMM) which has the following advantages: (1) it considers both individual and collective movement patterns in making prediction, (2) it is effective even when the trajectory data is sparse, (3) it considers the time factor and builds models that are suited to different time periods. We have conducted extensive experiments on a real dataset, and the results demonstrate the superiority of NLPMM over existing methods.</abstract>
	</paper>
	<paper>
		<ID>87</ID>
		<title>Inferring Attitude in Online Social Networks Based on Quadratic Correlation</title>
		<authors>Cong Wang (Simon Fraser University),Andrei Bulatov (Simon Fraser University)</authors>
		<abstract>The structure of an online social network in most cases cannot be described just by links between its members. We study online social networks, in which members may have certain attitude, positive or negative, toward each other, and so the network consists of a mixture of both positive and negative relationships. Our goal is to predict the sign of a given relationship based on the evidences provided in the current snapshot of the network. More precisely, using machine learning techniques we develop a model that after being trained on a particular network predicts the sign of an unknown or hidden link. The model uses relation- ships and influences from peers as evidences for the guess, however, the set of peers used is not predefined but rather learned during the training process. We use quadratic correlation between peer members to train the predictor. The model is tested on popular online datasets such as Epinions, Slashdot, and Wikipedia. In many cases it shows almost perfect predic- tion accuracy. Moreover, our model can also be efficiently updated as the underlying social network evolves.</abstract>
	</paper>
	<paper>
		<ID>89</ID>
		<title>Learning from Crowds under Experts’ Supervision</title>
		<authors>Qingyang Hu (Zhejiang University),Qinming He (),Hao Huang (),Kevin Chiew (),Zhenguang Liu ()</authors>
		<abstract>Crowdsourcing services have been proven efficient in collecting large amount of labeled data for supervised learning, but low cost of crowd workers leads to unreliable labels. Various methods have been proposed to infer the ground truth or learn from crowd data directly though, there is no guarantee that these methods work well for highly biased or noisy crowd labels. Motivated by this limitation of crowd data, we propose to improve the performance of crowdsourcing learning tasks with some additional expert labels by treating each labeler as a personal classifier and combining all labelers' opinions from a model combination perspective. Experiments show that our method can significantly improve the learning quality as compared with those methods solely using crowd labels.</abstract>
	</paper>
	<paper>
		<ID>92</ID>
		<title>Balancing the Analysis of Frequent Patterns</title>
		<authors>Arnaud Giacometti (University of Tours),Dominique Li (University of Tours),Arnaud Soulet (University of Tours)</authors>
		<abstract>A main challenge in pattern mining is to focus the discovery on high-quality patterns. One popular solution is to compute a numerical score on how well each discovered pattern describes the data. The best rating patterns are then the most analyzed by the data expert. In this paper, we evaluate the quality of discovered patterns by anticipating of how user analyzes them. We show that the examination of frequent patterns with the notion of support led to an unbalanced analysis of the dataset. Certain transactions are indeed completely ignored. Hence, we propose the notion of balanced support that weights the transactions to let each of them receive user specified attention. We also develop an algorithm ABSOLUTE for calculating these weights leading to evaluate the quality of patterns. Our experiments on frequent itemsets validate its effectiveness and show the relevance of the balanced support.</abstract>
	</paper>
	<paper>
		<ID>95</ID>
		<title>MultiAspectSpotting: Spotting Anomalous Behavior within Count Data using Tensor</title>
		<authors>Koji Maruhashi (Fujitsu Laboratories Ltd.),Nobuhiro Yugami (Fujitsu Laboratories Ltd.)</authors>
		<abstract>Methods for finding anomalous behaviors are attracting much attention, especially for very large datasets with several attributes with tens of thousands of categorical values. For example, security engineers try to find anomalous behaviors, i.e., remarkable attacks which greatly differ from the day's trend of attacks, on the basis of intrusion detection system logs with source IPs, destination IPs, port numbers, and additional information. However, there are large amount of abnormal records caused by noise, which can be repeated more abnormally than those caused by anomalous behaviors, and they are hard to be distinguished from each other. To tackle these difficulties, we propose a two-step anomaly detection. First, we detect abnormal records as individual anomalies by using a statistical anomaly detection, which can be improved by Poisson Tensor Factorization. Next, we gather the individual anomalies into groups of records with similar attribute values, which can be implemented by CANDECOMP/PARAFAC Decomposition. We conduct experiments using datasets added with synthesized anomalies and prove that our method can spot anomalous behaviors effectively. Moreover, our method can spot interesting patterns within some real world datasets such as IDS logs and web-access logs.</abstract>
	</paper>
	<paper>
		<ID>98</ID>
		<title>Visual Analysis of Uncertainty in Trajectories</title>
		<authors>Lu Lu (HKUST),Nan Cao (IBM T.J. Watson),Siyuan Liu (CMU),Lionel Ni (Hong Kong University of Science of Technology),Xiaoru Yuan (Peking University),Huamin Qu (Hong Kong University of Science of Technology)</authors>
		<abstract>Mining trajectory data has many important applications. Real trajectory data often involve uncertainty due to inadequate sampling rates and measurement errors. For some trajectories, their precise positions cannot be recovered and the exact routes that vehicles traveled cannot be accurately reconstructed. In this paper, we investigate the uncertainty problem in trajectory data and present a visual analytics system to reveal, analyze, and solve the uncertainties associated with trajectory samples. We first propose two novel visual encoding schemes called the road map analyzer and the uncertainty lens for discovering road map errors and visually analyzing the uncertainty in trajectory data respectively. Then, we conduct three case studies to discover the map errors, to address the ambiguity problem in map-matching, and to reconstruct the trajectories with historical data. These case studies demonstrate the feasibility and effectiveness of our system.</abstract>
	</paper>
	<paper>
		<ID>104</ID>
		<title>Analyzing Location Predictability on Location-Based Social Networks</title>
		<authors>Defu Lian (University of Science and Technology of China),Yin Zhu (The Hongkong university of Science and Technology),Xing Xie (Microsoft Research Asia, China),Enhong Chen (University of Science and Technology of China, China)</authors>
		<abstract>With the growing popularity of location-based social networks, vast amount of user check-in histories have been accumulated. Based on such historical data, predicting a user's next check-in place is of much interest recently. There is, however, little study on the limit of predictability of this task and its correlation with users' demographics. These studies can give deeper insight to the prediction task and bring valuable insights to the design of new prediction algorithms. In this paper, we carry out a thorough study on the limit of check-in location predictability, i.e., to what extent the next locations are predictable, in the presence of special properties of check-in traces. Specifically, we begin with estimating the entropy of an individual check-in trace and then leverage Fano's inequality to transform it to predictability. Extensive analysis has then been performed on two large-scale check-in datasets from Jiepang and Gowalla with 36M and 6M check-ins, respectively. As a result, we find $25\%$ and $38\%$ potential predictability respectively. Finally, the correlation analysis between predictability and users' demographics has been performed. The results show that the demographics, such as gender and age, are significantly correlated with location predictability.</abstract>
	</paper>
	<paper>
		<ID>112</ID>
		<title>Crowdordering</title>
		<authors>Toshiko Matsui (),Yukino Baba (The University of Tokyo),Toshihiro Kamishima (National Institute of Advanced Industrial Science and Technology, Japan),Hisashi Kashima ()</authors>
		<abstract>Crowdsourcing is a promising solution to problems that are difficult for computers, but relatively easy for humans. One of the biggest challenges in crowdsourcing is quality control, since high quality results cannot be expected from crowdworkers who are not necessarily very capable or motivated. Several statistical crowdsourcing quality control methods for binary and multinomial questions have been proposed. In this paper, we consider tasks where crowdworkers are asked to arrange multiple items in the correct order. We propose a probabilistic generative model of crowd answers by extending a distance-based order model to incorporate worker ability, and propose an efficient estimation algorithm. Experiments using real crowdsourced datasets show the advantage of the proposed method over a baseline method.</abstract>
	</paper>
	<paper>
		<ID>115</ID>
		<title>Supervised Nonlinear Factorizations Excel In Semi-supervised Regression</title>
		<authors>Josif Grabocka (University of Hildesheim),Erind Bedalli (University of Tirana),Lars Schmidt-Thieme (University of Hildesheim)</authors>
		<abstract>Semi-supervised learning is an eminent domain of machine learning focusing on real-life problems where the labeled data instances are scarce. This paper innovatively extends existing factorization models into a supervised nonlinear factorization. The current state of the art methods for semi-supervised regression are based on supervised manifold regularization. In contrast, the latent data constructed by the proposed method jointly reconstructs both the observed predictors and target variables via generative-style nonlinear functions. Dual-form solutions of the nonlinear functions and a stochastic gradient descent technique which learns the low dimensionality data are introduced. The validity of our method is demonstrated in a series of experiments against five state-of-art baselines, clearly improving the prediction accuracy in eleven real-life data sets.</abstract>
	</paper>
	<paper>
		<ID>118</ID>
		<title>Intervention-Driven Predictive Framework for Modeling Healthcare Data</title>
		<authors>Santu Rana (Deakin University),Sunil Gupta (Deakin University),Dinh Phung (Deakin University, Australia ),Svetha Venkatesh (Deakin University)</authors>
		<abstract>Assessing prognostic risk is crucial to clinical care, and critically dependent on both diagnosis and medical interventions. Current methods use this augmented information to build a single prediction rule. But this may not be expressive enough to capture differential effects of interventions on prognosis. To this end, we propose a supervised, Bayesian nonparametric framework that simultaneously discovers the latent intervention groups and builds a separate prediction rule for each intervention group. The prediction rule is learnt using diagnosis data through a Bayesian logistic regression. For inference, we develop an efficient collapsed Gibbs sampler. We demonstrate that our method outperforms baselines in predicting 30-day hospital readmission using two patient cohorts - Acute Myocardial Infarction and Pneumonia. The significance of this model is that it can be applied widely across a broad range of medical prognosis tasks.</abstract>
	</paper>
	<paper>
		<ID>119</ID>
		<title>Shifting Hypergraphs by Probabilistic Voting</title>
		<authors>Yang Wang (UNSW),Xuemin Lin (The University of New South Wales, Australia),Qing Zhang (Australia e-health research center),Lin Wu (UNSW)</authors>
		<abstract>In this paper, we develop a novel paradigm, namely hypergraph shift, to find robust graph modes by probabilistic voting strategy, which are semantically sound besides the self-cohesiveness requirement in forming graph modes. Unlike the existing techniques to seek graph modes by shifting vertices based on pair-wise edges (i.e, an edge with $2$ ends), our paradigm is based on shifting high-order edges (hyperedges) to deliver graph modes. Specifically, we convert the problem of seeking graph modes as the problem of seeking maximizers of a novel objective function with the aim to generate good graph modes based on sifting edges in hypergraphs. As a result, the generated graph modes based on dense subhypergraphs may more accurately capture the object semantics besides the self-cohesiveness requirement. We also formally prove that our technique is always convergent. Extensive empirical studies on synthetic and real world data sets are conducted on clustering and graph matching. They demonstrate that our techniques significantly outperform the existing techniques.</abstract>
	</paper>
	<paper>
		<ID>121</ID>
		<title>Structure-aware Distance Measures for Comparing Clusterings in Graphs</title>
		<authors>Jeffrey Chan (University of Melbourne),Xuan Vinh Nguyen (University of Melbourne, Australia),Wei Liu (NICTA),James Bailey (University of Melbourne, Australia),Christopher Leckie (University of Melbourne),Kotagiri Ramamohanarao (University of Melbourne),Jian Pei (Simon Fraser University, Canana)</authors>
		<abstract>Clustering in graphs aims to group vertices with similar patterns of connections.  Applications include discovering communities and latent structures in graphs.  Many algorithms have been proposed to find graph clusterings, but an open problem is the need for suitable comparison measures to quantitatively validate these algorithms, performing consensus clustering and to track evolving (graph) clusters across time.  To date, most comparison measures have focused on comparing the vertex groupings, and completely ignore the difference in the structural approximations in the clusterings, which can lead to counter-intuitive comparisons.  In this paper, we propose new measures that account for differences in the approximations.  We focus on comparison measures for two important graph clustering approaches, community detection and blockmodelling, and propose comparison measures that work for weighted (and unweighted) graphs.</abstract>
	</paper>
	<paper>
		<ID>122</ID>
		<title>CTROF: A Collaborative Tweet Ranking Framework for Online Personalized Recommendation</title>
		<authors>Kaisong Song (Northeastern University),Daling Wang (northeastern university(China)),Shi Feng (Northeastern University(China)),Wen Qu (),Ge Yu (Northeastern University(China)),Yifei Zhang (Northeastern University in P. R. China)</authors>
		<abstract>Current social media services like Twitter and Sina Weibo have become an indispensable platform, and provide a large number of real-time messages. However, users are often overwhelmed with large amounts of information delivered via their followees, and may miss out on much enjoyable or useful content. An information overload problem has troubled many users, especially those with many followees and thousands of tweets arriving every day. In this case, real-time personalized recommendation plays an extreme important role in microblog, which needs analyzing users’ preference and recommending most relevant and newest content. Both of them pose serious challenges. In this paper, we focus on personal online tweet recommendation and propose a Collaborative Tweet Ranking Online Framework (CTROF) for the recommendation, which has integrated the Optimized Collaborative Tweet Ranking model CTR+ and Reservoir Sampling algorithm together. The experiment conducted on a real dataset from Sina microblog shows good performance and our algorithm outperforms the other baseline methods.</abstract>
	</paper>
	<paper>
		<ID>123</ID>
		<title>Two-Phase Layered Learning Recommendation via Category Structure</title>
		<authors>Ke Ji (Beijing Jiaotong University),Shen Hong (Beijing Jiaotong University),Tian Hui (),Yanbo Wu (),Jun Wu (Beijing Jiaotong University)</authors>
		<abstract>Context and social network information have been introduced to improve recommendation systems. However, most existing work still models users' rating for every item directly. This approach has two disadvantages: high cost for handling large amount of items and unable to handle the dynamic update of items. Generally, items are classified into many categories. Items in the same category have similar/relevant content, and hence may attract users of the same interest. These characteristics determine that we can utilize the item's content similarity to overcome the difficultiess of large amount and dynamic update of items. In this paper, aiming at fusing the category structure, we propose a novel two-phase layered learning recommendation framework, which is matrix factorization approach and can be seen as a greedy layer-wise training: first learn user's average rating to every category, and then, based on this, learn more accurate estimates of user's rating for individual item with content and social relation ensembled. Based on two kinds of classifications, we design two layered gradient algorithms in our framework. Systematic experiments on real data demonstrate that our algorithms outperform other state-of-the-art methods, especially for recommending new items.</abstract>
	</paper>
	<paper>
		<ID>128</ID>
		<title>Hash-based Stream LDA: Topic Modeling in Social Streams</title>
		<authors>Anton Slutsky (Drexel University),Xiaohua Hu (Drexel University, USA),Yuan An (Drexel University)</authors>
		<abstract>We study the problem of topic modeling in continuous social media streams and propose a new generative probabilistic model called Hash-Based Stream LDA (HS-LDA), which is a generalization of the popular LDA approach. The model differs from LDA in that it exposes facilities to include inter- document similarity in topic modeling. The corresponding inference algorithm outlined in the paper relies on efficient estimation of document similarity with Locality Sensitive Hashing to retain the knowledge of past social discourse in a scalable way. The historical knowledge of previous messages is used in inference to improve quality of topic discovery. Performance of the new algorithm was evaluated against classical LDA approach as well as the streamoriented On-line LDA and SparseLDA using data sets collected from the Twitter microblog system and an IRC chat community. Experimental results showed that HS-LDA outperformed other techniques by more than 12% for the Twitter dataset and by 21% for the IRC data in terms of average perplexity.</abstract>
	</paper>
	<paper>
		<ID>130</ID>
		<title>Crime Forecasting Using Spatio-Temporal Pattern with Ensemble Learning</title>
		<authors>Chung-Hsien Yu (University of Massachusetts Bo),Wei Ding (University of Massachusetts Boston, USA),Ping Chen (University of Massachusetts Boston),Melissa Morabito (University of Massachusetts Lowell)</authors>
		<abstract>Crime forecasting is notoriously difficult. A crime incident is a multi-dimensional complex phenomenon that is closely associated with temporal, spatial, societal, and ecological factors. In an attempt to utilize all these factors in crime pattern formulation, we propose a new feature construction and feature selection framework for crime forecasting. A new concept of multi-dimensional feature denoted as spatio-temporal pattern, is constructed from local crime cluster distributions in different time periods at different granularity levels. We design and develop the Cluster-Confidence-Rate-Boosting (CCRBoost) algorithm to efficiently select relevant local spatio-temporal patterns to construct a global crime pattern from a training set. This global crime pattern is then used for future crime prediction. Using data from January 2006 to December 2009 from a police department in a northeastern city in the US, we evaluate the proposed framework on residential burglary prediction. The results show that the proposed CCRBoost algorithm has achieved about 80% on accuracy in predicting residential burglary using the grid cell of 800-meter by 800-meter in size as one single location.</abstract>
	</paper>
	<paper>
		<ID>136</ID>
		<title>Multi-Instance Learning from Positive and Unlabeled Bags</title>
		<authors>Jia Wu (QCIS Lab, UTS),Xingquan Zhu (Florida Atlantic University, USA),Chengqi Zhang (University of Technology Sydney, Australia),Zhihua Cai (China University of Geosciences)</authors>
		<abstract>Many methods exist to solve multi-instance learning by using different mechanisms, but all these methods require that both positive and negative bags are provided for learning. In reality, applications may only have positive samples to describe users’ learning interests and remaining samples are unlabeled (which may be positive, negative, or irrelevant to the underlying learning task). In this paper, we formulate this problem as positive and unlabeled multi-instance learning (puMIL). The main challenge of puMIL is to accurately identify negative bags for training discriminative classification models. To solve the challenge, we assign a weight value to each bag, and use an Artificial Immune System based self-adaptive process to select most reliable negative bags in each iteration. For each bag, a most positive instance (for a positive bag) or a least negative instance (for an identified negative bag) is selected to form a positive margin pool (PMP). A weighted kernel function is used to calculate pairwise distances between instances in the PMP, with the distance matrix being used to learn a support vector machines classifier. A test bag is classified as positive if one or multiple instances inside the bag are classified as positive, and negative otherwise. Experiments on real-world data demonstrate the algorithm performance.</abstract>
	</paper>
	<paper>
		<ID>140</ID>
		<title>A New Evaluation Function for Entropy-based Feature Selection from Incomplete Data</title>
		<authors>Wenhao Shu (Beijing Jiaotong University),Shen Hong (),Yingpeng Sang (),Yidong Li (Beijing Jiaotong Univeristy, China),Jun Wu (Beijing Jiaotong University)</authors>
		<abstract>In data mining and knowledge discovery, evaluation functions for evaluating the quality of features have great influence on the outputs of feature selection algorithms. However, in the existing entropy-based feature selection algorithms from incomplete data, evaluation functions are often inadequately computed as a result of two drawbacks. One is that the existing evaluation functions have not taken into consideration the differences of discernibility abilities of features. The other is that in the feature selection algorithms of forward greedy search, if the feature with the same entropy value is not only one, the arbitrary selection may affect the classification performance. This paper introduces a new evaluation function to overcome the drawbacks. A main advantage of the proposed evaluation function is that the granularity of classification is considered in the evaluation computations for candidate features. Based on the new evaluation function, an entropy-based feature selection algorithm from incomplete data is developed. Experimental results show that the proposed evaluation function is more effective than the existing evaluation functions in terms of classification accuracy.</abstract>
	</paper>
	<paper>
		<ID>147</ID>
		<title>Visualization of PICO Elements for Information Needs Clarification and Query Refinement</title>
		<authors>Patrick Then (Swinburne Univ of Technology),Wan-Tze Vong (Swinburne University of Techno)</authors>
		<abstract>The UMLS semantic types and natural language processing techniques were collectively utilized to extract PICO elements from the titles and abstracts of 114 MEDLINE articles. 24 sets of PICO elements were generated from the articles based on the derivation of, and the tokenization methods and weighting schemes applied to the elements. The similarity of the I and C elements (called jointly the “Interventions”) between pairs of documents was calculated using 42 similarity/distance measures. Similar interventions were grouped together using complete-/average-/ward-link hierarchical clustering. The similarity measure, Yule, performed significantly better than other measures in identifying paired interventions derived from the titles and which had been pre-processed into single term and weighted by binary term-occurrence. The clustering algorithm, complete-link, provides the most appropriate structure for the visualization of interventions. Similarity-based clustering gave a higher mean average precision than random-baseline clustering (MAP = 0.4298 vs. 0.2364) over the 25 queries evaluated. </abstract>
	</paper>
	<paper>
		<ID>148</ID>
		<title>Inferring Strange Behavior from Connectivity Pattern in Social Networks</title>
		<authors>Meng Jiang (Tsinghua University),Peng Cui (Tsinghua University),Alex Beutel (),Christos Faloutsos (CMU),Shiqiang Yang ()</authors>
		<abstract>Given a multimillion-node social network, how can we summarize connectivity pattern from the data, and how can we find unexpected user behavior? In this paper we study a complete graph from a large who-follows-whom network and spot lockstep behavior that large groups of followers connect to the same groups of followees. Our first contribution is that we study strange patterns on the adjacency matrix and in the spectral subspaces with respect to several flavors of lockstep. We discover that (a) the lockstep behavior on the graph shapes dense ``block'' in its adjacency matrix and creates ``ray'' in spectral subspaces, and (b) partially overlapping of the behavior shapes ``staircase'' in the matrix and creates ``pearl'' in the subspaces. The second contribution is that we provide a fast algorithm, using the discovery as a guide for practitioners, to detect users who offer the lockstep behavior. We demonstrate that our approach is effective on both synthetic and real data.</abstract>
	</paper>
	<paper>
		<ID>164</ID>
		<title>Mining Biomedical Literature and Ontologies for Drug Repositioning Discovery</title>
		<authors>Chih-Ping Wei (National Taiwan University, Taiwan),Kuei-An Chen (National Taiwan University),Lien-Chin Chen (National Taiwan University)</authors>
		<abstract>Drug development is time-consuming, costly, and risky. Approximate 80% to 90% of drug development projects fail before they ever get into clinical trials. To reduce the high risk of failure for drug development, pharmaceutical companies are exploring the drug repositioning approach for drug development. Previous studies have shown the feasibility of using computational methods to help extract plausible drug repositioning candidates, but they all encountered some limitations. In this study, we propose a novel drug-repositioning discovery method that takes into account multiple information sources, including more than 18,000,000 biomedical research articles and some existing ontologies that cover detailed relations between drugs, proteins and diseases. We design two experiments to evaluate our proposed drug repositioning discovery method. Overall, our evaluation results demonstrate the capability and superiority of our proposed drug repositioning method for discovering potential, novel drug-disease relationships.</abstract>
	</paper>
	<paper>
		<ID>166</ID>
		<title>Detecting Changes in Rare Patterns from Data Streams</title>
		<authors>David Tse Jung Huang (University of Auckland),Yun Sing Koh (University of Auckland),Gillian Dobbie (University of Auckland),Russel Pears (Auckland University of Technology)</authors>
		<abstract>Current drift detection techniques in data streams focus on finding changes in streams with labeled data intended for supervised machine learning methods. Up to now there has been no research that considers drift detection on item based data streams with unlabeled data intended for unsupervised association rule mining. In this paper we address and discuss the current issues in performing drift detection of rare patterns in data streams and present a working approach that enables the detection of rare pattern changes. We propose a novel measure, called the $M$ measure, that facilitates pattern change detection and through our experiments we show that this measure can be used to detect changes in rare patterns in data streams efficiently and accurately.</abstract>
	</paper>
	<paper>
		<ID>174</ID>
		<title>Subtopic Mining via Modifier Graph Clustering</title>
		<authors>Haitao Yu (The University of Tokushima),Fuji Ren (The University of Tokushima)</authors>
		<abstract>Understanding the information need encoded in a user query has long been regarded as a crucial step of effective information retrieval. In this paper, we focus on subtopic mining that aims at generating a ranked list of subtopic strings for a given topic. We propose the modifier graph based approach, under which the problem of subtopic mining reduces to that of graph clustering over the modifier graph. Compared with the existing methods, the experimental results show that our modifier-graph based approaches are robust to the sparseness problem. In particular, our approaches that perform subtopic mining at a fine-grained term-level outperform the baseline methods that perform subtopic mining at a whole query-level in terms of I-rec, D-nDCG and D#-nDCG.</abstract>
	</paper>
	<paper>
		<ID>177</ID>
		<title>Extracting Diverse Patterns with Unbalanced Concept Hierarchy</title>
		<authors>Kumara Swamy Mittapally (International Institute of Information Technology, Hyderabad),P. Reddy (International Institute of Information Technology, Hyderabad (IIIT-H), India),Somya Srivatsava (Amazon)</authors>
		<abstract>The process of frequent pattern extraction finds interesting information about the association among the items in a transactional database. The notion of support is employed to extract the frequent patterns. Normally, in a given domain, a set of items can be grouped into a category and a pattern may contain the items which belong to multiple categories. In several applications, it may be useful to distinguish between the pattern having items belonging to multiple categories and the pattern having items belonging to one or a few categories. The notion of diversity captures the extent the items in the pattern belong to multiple categories. The items and the categories form a concept hierarchy. In the literature, an approach has been proposed to rank the patterns by considering the balanced concept hierarchy. In a real life scenario, the concept hierarchies are normally unbalanced. In this paper, we propose a general approach to calculate the rank based on the diversity, called drank, by considering the unbalanced concept hierarchy. The experiment results show that the patterns ordered based on drank are different from the patterns ordered based on support, and the proposed approach could assign the drank to different kinds of unbalanced patterns.</abstract>
	</paper>
	<paper>
		<ID>178</ID>
		<title>Semi-supervised Feature Analysis for Multimedia Annotation by Mining Label Correlation</title>
		<authors>Xiaojun Chang (The University of Queensland),Haoquan Shen (Zhejiang University),Sen Wang (The University of Queensland),Jiajun Liu (CSIRO),Xue Li (The University of Queensland, Australia)</authors>
		<abstract>In multimedia annotation, labeling a large amount of training data by human is both time-consuming and tedious. Therefore, to automate this process, a number of methods that leverage unlabeled training data have been proposed. Normally, a given multimedia sample is associated with multiple labels, which may have inherent correlations in real world. Classical multimedia annotation algorithms address this problem by decomposing the multi-label learning into multiple independent single-label problems, which ignores the correlations between different labels. In this paper, we combine label correlation mining and semi-supervised feature selection into a single framework. We evaluate performance of the proposed algorithm of multimedia annotation using MIML, MIRFLICKR and NUS-WIDE datasets. Mean average precision (MAP), MicroAUC and MacroAUC are used as evaluation metrics. Experimental results on the multimedia annotation task demonstrate that our method outperforms the state-of-the-art algorithms for its capability of mining label correlations and exploiting both labeled and unlabeled training data.</abstract>
	</paper>
	<paper>
		<ID>183</ID>
		<title>A Robust Classifier for Imbalanced Datasets</title>
		<authors>Sori Kang (The University of Melbourne),Kotagiri Ramamohanarao (University of Melbourne)</authors>
		<abstract>Imbalanced dataset classification is a challenging problem, since many classifiers are sensitive to class distribution so that the clas- sifiers’ prediction has bias towards majority class. Hellinger Distance has been proven that it is skew-insensitive and the decision trees that employ Hellinger Distance as a splitting criterion have shown better performance than other decision trees based on Information Gain. We propose a new decision tree induction classifier (HeDEx) based on Hellinger Distance that is randomized ensemble trees selecting both attribute and split-point at random. We also propose hyperplane as a decision surface for HeDEx to improve the performance. A new pattern-based oversampling method is also proposed in this paper to reduce the bias towards majority class. The patterns are detected from HeDEx and the new instances generated are applied after verification process using Hellinger Distance Decision Trees. Our experiments show that the proposed methods show perfor- mance improvements on imbalanced datasets over the state-of-the-art Hellinger Distance Decision Trees.</abstract>
	</paper>
	<paper>
		<ID>188</ID>
		<title>A Fast Secure Dot Product Protocol with Application to Privacy Preserving Association Rule Mining</title>
		<authors>Changyu Dong (University of Strathclyde),Liqun Chen (HP Labs)</authors>
		<abstract>Data mining often causes privacy concerns. To ease the concerns, various privacy preserving data mining techniques have been proposed. However, those techniques are often too computationally intensive to be deployed in practice. Efficiency becomes a major challenge in privacy preserving data mining. In this paper we present an efficient secure dot product protocol and show its application in privacy preserving association rule mining, one of the most widely used data mining techniques. The protocol is orders of magnitude faster than previous protocols because it employs mostly cheap cryptographic operations, e.g. hashing and modular multiplication. The performance has been further improved by parallelization. We implemented the protocol and tested the performance. The test result shows that on moderate commodity hardware, the dot product of two vectors of size 1 million can be computed within 1 minute. As a comparison, the currently most widely used protocol needs about 1 hour and 23 minutes.</abstract>
	</paper>
	<paper>
		<ID>190</ID>
		<title>Inferring Metapopulation Based Disease Transmission Networks</title>
		<authors>Xiaofei Yang (Hong Kong Baptist University),Jiming Liu (Hong Kong Baptist University, Hong Kong),Kwok Wai Cheung (),Xiaonong Zhou ()</authors>
		<abstract>To investigate how an infectious disease spreads, it is most desirable to discover the underlying disease transmission networks based on surveillance data. Existing studies have provided some methods for inferring information diffusion networks, where nodes correspond to individual persons. However, in the case of disease transmission, to effectively develop intervention strategies, it would be more realistic and reasonable for policy makers to study the diffusion patterns at the metapopulation level, that is, to consider disease transmission networks where nodes represent subpopulations, and links indicate their interrelationships. Such networks are useful to: (i) investigate hidden factors that influence epidemic dynamics, (ii) reveal possible sources of epidemic outbreaks, and (iii) practically develop and improve strategies for disease control. Therefore, based on such a real-world motivation, we aim to address the problem of inferring disease transmission networks at the metapopulation level. Specifically, we propose an inference method called NetEpi (Network Epidemic), and evaluate the method by utilizing synthetic and real-world datasets. The experiments show that NetEpi can recover most of the ground-truth disease transmission networks based only on the surveillance data. Moreover, it can help detect and interpret patterns and transmission pathways from the real-world data.</abstract>
	</paper>
	<paper>
		<ID>196</ID>
		<title>Dynamic Circle Recommendation: A Probabilistic Model</title>
		<authors>Fan-Kai Chou (National Chiao Tung University),Meng-Fen Chiang (),Yi-Cheng Chen (),Wen-Chih Peng (National Chiao Tung University, Taiwan)</authors>
		<abstract>This paper presents a novel framework for dynamic circle recommendation for a query user at a given time point from historical communication logs. We identify the fundamental factors that govern interactions and aim to automatically form dynamic circle for scenarios, such as, who should I dial to in the early morning? whose mail would I reply first at midnight? We develop a time-sensitive probabilistic model (TCircleRank) that not only captures temporal tendencies between the query user and candidate friends but also blends frequency and recency into group formation. We also utilize the model to support two types of dynamic circle recommendation: Seedset Generation: single-interaction suggestion and Circle Suggestion: multiple interactions suggestion. We further present approaches to infer relevant time interval in determining circles for a query user at a given time. Experimental results on Enron dataset, Call Detail Records and Reality Mining Data prove the effectiveness of dynamic circle recommendation using TCircleRank.</abstract>
	</paper>
	<paper>
		<ID>200</ID>
		<title>Mining Contrast Subspaces</title>
		<authors>Lei Duan (Sichuan University),Guanting Tang (Simon Fraser University),Jian Pei (Simon Fraser University, Canana),James Bailey (University of Melbourne, Australia),Guozhu Dong (Wright State University, USA),Akiko Campbell (Pacific Blue Cross),Changjie Tang (Sichuan University)</authors>
		<abstract>In this paper, we tackle a novel problem of mining contrast subspaces.  Given a set of multidimensional objects in two classes C+ and C- and a query object o, we want to find top-k subspaces S that maximize the ratio of likelihood of o in C+ against that in C-. We demonstrate that this problem has important applications, and at the same time, is very challenging. It even does not allow polynomial time approximation.  We present CSMiner, a mining method with various pruning techniques.  CSMiner is substantially faster than the baseline method.  Our experimental results on real data sets verify the effectiveness and efficiency of our method.</abstract>
	</paper>
	<paper>
		<ID>202</ID>
		<title>Shingled Graph Disassembly: Finding the Undecideable Path</title>
		<authors>Richard Wartell (Mandiant),Yan Zhou (University of Texas at Dallas),Kevin Hamlen (University of Texas at Dallas),Murat Kantarcioglu (University of Texas at Dallas, USA)</authors>
		<abstract>A probabilistic finite state machine approach to statically disassembling x86 machine language programs is presented and evaluated. Static disassembly is a crucial prerequisite for software reverse engineering, and has many applications in computer security and binary analysis. The general problem is provably undecidable because of the heavy use of unaligned instruction encodings and dynamically computed control flows in the x86 architecture. Limited work in machine learning and data mining has been undertaken on this subject. This paper shows that semantic meanings of opcode sequences can be leveraged to infer similarities between groups of opcode and operand sequences. This empowers a probabilistic finite state machine to learn statistically significant opcode and operand sequences in a training corpus of disassemblies. The similarities demonstrate the statistical significance of opcodes and operands in a surrounding context, facilitating more accurate disassembly of new binaries. Empirical results demonstrate that the algorithm is more efficient and effective than comparable approaches used by state-of-the-art disassembly tools.</abstract>
	</paper>
	<paper>
		<ID>204</ID>
		<title>Efficiently Depth-First Minimal Pattern Mining</title>
		<authors>Arnaud Soulet (University of Tours),François Rioult (University of Caen)</authors>
		<abstract>Condensed representations have been studied extensively for 15 years. In particular, the maximal patterns of the equivalence classes have received much attention with very general proposals. In contrast, the minimal patterns remained in the shadows in particular because of their difficult extraction. In this paper, we present a generic framework for minimal patterns mining by introducing the concept of minimizable set system. This framework addresses various languages such as itemsets or strings, and at the same time, different metrics such as frequency. For instance, the free and the essential patterns are naturally handled by our approach, just as the minimal strings. Then, for any minimizable set system, we introduce a fast minimality check that is easy to incorporate in a depth-first search algorithm for mining the minimal patterns. We demonstrate that it is polynomial-delay and polynomial-space. Experiments on traditional benchmarks complete our study.</abstract>
	</paper>
	<paper>
		<ID>205</ID>
		<title>Mining Diversified Shared Decision Tree Sets for Discovering Cross Domain Similarities</title>
		<authors>Guozhu Dong (Wright State University, USA),Qian Han (Deloitte Financial Advisory Services)</authors>
		<abstract>This paper studies the problem of mining diversified sets of shared decision trees (SDTs). Given two datasets representing two application domains, an SDT is a decision tree that can classify both datasets and also captures class-based population-structure similarity between the two datasets. Previous studies motivated the SDT mining problem but considered mining just one SDT. The present paper goes beyond mining just one SDT and considers mining a small set of diversified SDTs having two properties: (1) each SDT has high quality with respect to “shared” accuracy and population-structure similarity and (2) different SDTs in the set are very different from each other. A diversified set of SDTs can serve as a concise representative of highly diverse range of cross-domain similarities in the form of high quality SDTs, and it is more useful for selecting informative SDTs than a single SDT. This paper measures the diversity of a set of SDTs using aggregated difference among different SDTs’ usage of attributes. The paper provides effective algorithms to mine diversified sets of SDTs. Experimental results show that the algorithms are effective and can find diversified sets of high quality SDTs. </abstract>
	</paper>
	<paper>
		<ID>208</ID>
		<title>Com2: Fast Automatic Discovery of Temporal (’Comet’) Communities</title>
		<authors>Miguel Araujo (CMU),Spiros Papadimitriou (Rutgers University),Stephan Günnemann (Carnegie Mellon University),Christos Faloutsos (CMU),Prithwish Basu (BBN Technologies),Ananthram Swami (Army Research Laboratory),Evangelos Papalexakis (Carnegie Mellon University),Danai Koutra (Carnegie Mellon University)</authors>
		<abstract>Given a large network, changing over time, how can we find patterns and anomalies? We propose Com2, a novel and fast, incremental tensor analysis approach, which can discover both transient and periodic/repeating communities. The method is (a) scalable, being linear on the input size (b) general, (c) needs no user-defined parameters and (d) effective, returning results that agree with intuition. We apply our method on real datasets, including a phone-call one and a computer-traffic one. The phone call network consists of 4 million mobile users, with 51 million edges (phonecalls), over 14 days. Com2 spots intuitive patterns, that is, temporal communities (comet communities). We report our findings, which include large ’star’-like patterns, near-bipartite-cores, as well as tiny groups (5 users), calling each other hundreds of times within a few days. </abstract>
	</paper>
	<paper>
		<ID>213</ID>
		<title>Semi-supervised clustering on heterogeneous information networks</title>
		<authors>Chen Luo (College of Computer Science and Technology, Jilin University),Wei Pang (School of Natural and Computing Sciences, University of Aberdeen),Zhe Wang (College of Computer Science and Technology, Jilin University)</authors>
		<abstract>Semi-supervised clustering on information networks combines both the labeled and unlabeled data sets with an aim to improve the clustering performance. However, the existing semi-supervised clustering methods are all designed for homogeneous networks and do not deal with heterogeneous ones. In this work, we propose a semi-supervised clustering approach to analyze heterogeneous information networks, which include multi-typed objects and links and may contain more useful semantic information. The major challenge in the clustering task here is how to handle multi-relations and diverse semantic meanings in heterogeneous networks. In order to deal with this challenge, we introduce the concept of relation-path to measure the similarity between two data objects of the same type. Thereafter, we make use of the labeled information to extract different weights for all relation-paths. Finally, we propose SemiRPClus, a complete framework for semi-supervised learning in heterogeneous networks. Experimental results demonstrate the distinct advantages in effectiveness and efficiency of our framework in comparison with the baseline and some state-of-the-art approaches.</abstract>
	</paper>
	<paper>
		<ID>215</ID>
		<title>Fast Vertical Mining of Sequential Patterns Using Co-occurrence Information</title>
		<authors>Philippe Fournier-Viger (University of Moncton, Canada),Antonio Gomariz (University of Murcia),Manuel Campos (University of Murcia),Rincy Thomas (SCT)</authors>
		<abstract>Sequential pattern mining algorithms  using a vertical representation are the most efficient for mining sequential patterns in dense or long sequences, and  have excellent overall performance. The vertical representation allows generating patterns and calculating their supports without performing costly database scans. However, a crucial performance bottleneck of vertical algorithms is that they use a generate-candidate-and-test approach that can generate a large amount of infrequent candidates. To address this issue, we propose pruning candidates based on the study of item co-occurrences. We present a new structure named CMAP (Co-occurence MAP) for storing co-occurrence information. We explain how CMAP can be used to prune candidates in three state-of-the-art vertical algorithms, namely SPADE, SPAM and ClaSP. An extensive experimental study with six real-life datasets shows that (1) co-occurrence-based pruning is effective, (2) CMAP is very compact and that (3) the resulting algorithms outperform state-of-the-art algorithms for mining sequential patterns  (GSP, PrefixSpan, SPADE and SPAM) and closed sequential patterns  (ClaSP and CloSpan).</abstract>
	</paper>
	<paper>
		<ID>222</ID>
		<title>Machine Learning Approaches for Interactive Verification</title>
		<authors>Yu-Cheng Chou (National Taiwan University),Hsuan-Tien Lin (National Taiwan University, Taiwan)</authors>
		<abstract>Interactive verification is a new problem, which is closely related to active learning, but aims to query as many positive instances as possible within some limited query budget. We point out the similarity between interactive verification and another machine learning problem called contextual bandit. The similarity allows us to design interactive verification approaches from existing contextual bandit approaches. We compare the performance of those approaches on interactive verification. In particular, we propose to adopt the upper confidence bound (UCB) algorithm, which has been widely used for the contextual bandit, to solve the interactive verification problem. Experiment results demonstrate that UCB reaches superior performance for interactive verification on many real-world datasets. </abstract>
	</paper>
	<paper>
		<ID>229</ID>
		<title>Matrix Factorization Without User Data Retention</title>
		<authors>David Vallet (National ICT Australia),Arik Friedman (National ICT Australia),Shlomo Berkovsky (National ICT Australia)</authors>
		<abstract>Recommender systems often rely on a centralized storage of user data and there is a growing concern about the misuse of the data. As recent studies have demonstrated, sensitive information could be inferred from user ratings stored by recommender systems. This work presents a novel semi-decentralized variant of the widely-used Matrix Factorization (MF) technique. The proposed approach eliminates the need for retaining user data, such that neither user ratings nor latent user vectors are stored by the recommender. Experimental evaluation indicates that the performance of the proposed approach is close to that of standard MF, and that the gap between the two diminishes as more user data becomes available. Our work paves the way to a new type of MF recommenders, which avoid user data retention, yet are capable of achieving accuracy similar to that of the state-of-the-art recommenders.</abstract>
	</paper>
	<paper>
		<ID>231</ID>
		<title>Super Graph Classification</title>
		<authors>Ting Guo (QCIS Centre, UTS),Xingquan Zhu (Florida Atlantic University, USA)</authors>
		<abstract>Graphs are popularly used to represent objects with dependency structures, yet all existing graph classification algorithms can only handle simple graphs where each node is a single attribute (or a set of independent attributes). In this paper, we formulate a new super graph classification task where each node of the super graph may contain a graph (single attribute graph), so a super graph contains a set of inter connected graphs. To support super graph classification, we propose a Weighted Random Walk Kernel (WRWK) which generates a product graph between any two super graphs, and uses the similarity (kernel value) of two single attribute graph as the node weight. Then we calculate weighted random walks on the product graph to generate kernel value between two super graphs as their similarity. Our method enjoys sound theoretical properties, including bounded similarity. Experiments con firm that our method significantly outperforms baseline approaches.</abstract>
	</paper>
	<paper>
		<ID>234</ID>
		<title>Outlier Detection based on Leave-one-out Density using Binary Decision Diagrams</title>
		<authors>Takuro Kutsuna (Toyota Central R&amp;D Labs. Inc.),Akihiro Yamamoto (Kyoto University)</authors>
		<abstract>We propose a novel method for detecting outliers based on the leave-one-out density. The leave-one-out density of a datum is defined as a ratio of the number of data inside a region to the volume of the region after the datum is removed from an original data set. We propose an efficient algorithm that evaluates the leave-one-out density of each datum on a set of regions around the datum by using binary decision diagrams. The time complexity of the proposed method is near linear with respect to the size of a data set,  while the outlier detection accuracy is still comparable to other methods. Experimental results show the usefulness of the proposed method.</abstract>
	</paper>
	<paper>
		<ID>237</ID>
		<title>Noise-Tolerant Approximate Blocking for Dynamic Real-time Entity Resolution</title>
		<authors>Huizhi Liang (ANU),Yanzhe Wang (),Peter Christen (The Australian National University, Australia),Ross Gayler ()</authors>
		<abstract>Entity resolution is the process of identifying records in one or multiple data sources that represent the same real-world entity. This process needs to deal with noisy data that contain for example wrong pronunciation or spelling errors. Many real world applications require rapid responses for entity queries on dynamic datasets. This brings challenges to existing approaches which are mainly aimed at the batch matching of records in static data. Locality sensitive hashing (LSH) is an approximate blocking approach that hashes objects within a certain distance into the same block with high probability. How to make approximate blocking approaches scalable to large datasets and effective for entity resolution in real-time remains an open question. Targeting this problem, we propose a noise-tolerant approximate blocking approach to index records based on their distance ranges using LSH and sorting trees within large sized hash blocks. Experiments conducted on both synthetic and real-world datasets show the effectiveness of the proposed approach.</abstract>
	</paper>
	<paper>
		<ID>240</ID>
		<title>Forward Classification on Data Streams</title>
		<authors>Peng Wang (ICT, CAS),Peng Zhang (),Yanan Cao (),Li Guo (),Bingxing Fang ()</authors>
		<abstract>In this paper, we explore a new research problem of predicting an incoming classifier on dynamic data streams, named as forward classification. The state-of-the-art classification models on data streams, such as the incremental and ensemble models, fall into the retrospective classification category where models used for classification are built from past observed stream data and constantly lag behind the incoming unobserved test data. As a result, the classification model and test data are temporally inconsistent, leading to severe performance deterioration when the concept (joint probability distribution) evolves rapidly. To this end, we propose a new forward classification method which aims to build the classification model which fits the current data. Specifically, forward classification first predicts the incoming classifier based on a line of past built classifiers, and then uses the predicted classifier to classify current data chunk. A learning framework which can adaptively switch between forward classification and retrospective classification is also proposed.  Empirical studies on both synthetic and real-world data streams demonstrate the utility of the proposed method.</abstract>
	</paper>
	<paper>
		<ID>241</ID>
		<title>A Content-based Matrix Factorization Model for Recipe Recommendation</title>
		<authors>Chia-Jen Lin (National Taiwan University),Tsung-Ting Kuo (National Taiwan University),Shou-De Lin (National Taiwan University, Taiwan)</authors>
		<abstract>This paper aims at bringing recommendation to the culinary domain in recipe recommendation. Recipe recommendation possesses certain unique characteristics unlike conventional item recommendation, as a recipe provides detailed heterogeneous information about ingredients and cooking procedure. Thus, we propose to treat recipes as an aggregation of features, which are extracted from ingredients, categories, preparation directions, and nutrition facts. We then propose a content-driven matrix factorization approach to model the latent dimension of recipes, users, and features. We also propose novel bias terms to incorporate time-dependent features. The recipe dataset is available at http://mslab.csie.ntu.edu.tw/~tim/recipe.zip</abstract>
	</paper>
	<paper>
		<ID>249</ID>
		<title>MalSpot: Multi^2 Malicious Network Behavior Patterns Analysis</title>
		<authors>Ching-Hao Mao (III),Chung-Jung Wu (),Evangelos Papalexakis (Carnegie Mellon University),Christos Faloutsos (CMU),Kuo-Chen Lee (),Tien-Cheu Kao ()</authors>
		<abstract>What are the patterns that typical network attackers exhibit? For a given malicious network behaviors, are its attacks spread uniformly over time? In this work, we develop MalSpot, multi-resolution and multi-linear (Multi2) network analysis system in order to discover such malicious patterns, so that we can use them later for attack detection, when attacks are concurrent with legitimate traffic. We designed and deployed MalSpot, which employs multi-linear analysis with different time resolutions, running on top of MapReduce (Hadoop), and we identify patterns across attackers, attacked institutions and variation of time scales. We collect over a terabyte of proven malicious traces (along with benign ones), from the Taiwanese government security operation center (G-SOC) , during the entire year of 2012. We showcase the effectiveness of MalSpot, by discovering interesting patterns and anomalies on this enormous dataset. We observed static and time-evolving pat- terns, that a vast majority of the known malicious behavior seem to follow.</abstract>
	</paper>
	<paper>
		<ID>254</ID>
		<title>Improving iForest with relative mass</title>
		<authors>Sunil Aryal (Monash University),Kai Ming Ting (Monash University),Jonathan Wells (Monash University),Takashi Washio (Osaka University, Japan)</authors>
		<abstract>iForest uses a collection of isolation trees to detect anomalies. While it is effective in detecting global anomalies, it fails to detect local anomalies in data sets having multiple clusters of normal instances because the local anomalies are masked by normal clusters of similar density and they become less susceptible to isolation. In this paper, we propose a very simple but effective solution to overcome this limitation by replacing the global ranking measure based on path length with a local ranking measure based on relative mass that takes local data distribution into consideration. We demonstrate the utility of relative mass by improving the task specific performance of iForest in anomaly detection and information retrieval tasks.</abstract>
	</paper>
	<paper>
		<ID>255</ID>
		<title>Signed-Error Conformal Regression</title>
		<authors>Henrik Linusson (University of Borås),Ulf Johansson (University of Borås),Tuve Löfström (University of Borås)</authors>
		<abstract>This paper suggets a modification of the Conformal Prediction framework for regression that will strenghten the associated guarantee of validity. We motivate the need for this modification and argue that our conformal regressors are more closely tied to the actual error distribution of the underlying model, thus allowing for more natural interpretations of the prediction intervals. In the experimentation, we provide an empirical comparison of our conformal regressors to traditional conformal regressors and show that the proposed modification results in more robust two-tailed predictions, and more efficient one-tailed predictions.</abstract>
	</paper>
	<paper>
		<ID>259</ID>
		<title>Privacy-Preserving Collaborative Anomaly Detection for Participatory Sensing</title>
		<authors>Sarah Erfani (The University of Melbourne),Yee Wei Law (The University of Melbourne),Shanika Karunasekera (The University of Melbourne),Christopher Leckie (University of Melbourne),marimuthu Palaniswam ()</authors>
		<abstract>In collaborative anomaly detection, multiple data sources submit their data to an on-line service, in order to detect anomalies with respect to the wider population. A major challenge is how to achieve reasonable detection accuracy without disclosing the actual values of the participants' data. We propose a lightweight and scalable privacy-preserving collaborative anomaly detection scheme called Random Multiparty Perturbation (RMP), which uses a combination of nonlinear and participant-specific linear perturbation. Each participant uses an individually perturbed uniformly distributed random matrix, in contrast to existing approaches that use a common random matrix. A privacy analysis is given for Bayesian Estimation and Independent Component Analysis attacks. Experimental results on real and synthetic datasets using an auto-encoder show that RMP yields comparable results to non-privacy preserving anomaly detection. </abstract>
	</paper>
	<paper>
		<ID>261</ID>
		<title>Automatic Fake Followers Detection in Chinese Micro-blogging System</title>
		<authors>Yi Shen (CAS),jianjun Yu (),Kejun Dong (CNIC),Kai Nan ()</authors>
		<abstract>Micro-blogging, which has greatly influenced people's life, is experiencing fantastic success in the worldwide. However, during its rapid development, it has encountered the problem of content pollution. Various pollution in the micro-blogging platforms has hurt the credibility of micro-blogging and caused significantly negative effect. In this paper, we mainly focus on detecting fake followers which may lead to a problematic situation on social media networks. By extracting major features of fake followers in Sina Weibo, we propose a binary classifier to distinguish fake followers from the legitimate users. The experiments show that all the proposed features are important and our method greatly outperforms to detect fake followers. We also present an elaborate analysis on the phenomenon of fake followers, infer the supported algorithms and principles behind them, and finally provide several suggestions for micro-blogging systems and ordinary users to deal with the fake followers.</abstract>
	</paper>
	<paper>
		<ID>265</ID>
		<title>An Integrated Model for User Attribute Discovery: A Case Study on Political Affiliation Identification</title>
		<authors>Swapna Gottipati (Singapore Management Universit),Minghui Qiu (Singapore Management University),Yang Liu (Singapore Management University),Feida Zhu (Singapore Management University, Singapore),Jing Jiang (Singapore Management University)</authors>
		<abstract>Discovering user demographic attributes from social media is a problem of considerable interest. The problem setting can be generalized to include three components &#45;&#45;- users, topics and behaviors. In recent studies on this problem, however, the behavior between users and topics are not effectively incorporated. In our work, we proposed an integrated unsupervised model which takes into consideration all the three components integral to the task. Furthermore, our model incorporates collaborative filtering with probabilistic matrix factorization to solve the data sparsity problem, a computational challenge common to all such tasks. We evaluated our method on a case study of user political affiliation identification, and compared against state-of-the-art baselines. Our model achieved an accuracy of 70.1\ for user party detection task.</abstract>
	</paper>
	<paper>
		<ID>271</ID>
		<title>Data Augmented Maximum Margin Matrix Factorization for Flickr Group Recommendation</title>
		<authors>Liang Chen (Zhejiang University),Yilun Wang (Zhejiang University),Tingting Liang (Zhejiang University),Lichuan Ji (Zhejiang University),Jian Wu (Zhejiang University)</authors>
		<abstract>User groups on photo sharing Websites, such as Flickr, are self-organized communities to share photos and conversations with similar interest and have gained massive popularity. However, the huge volume of groups brings troubles for users to decide which group to choose. Further, directly applying collaborative filtering techniques to group recommendation will suffer from cold start problem since many users do not affiliate to any group. In this paper, we propose a hybrid recommendation approach named Data Augmented Maximum Margin Matrix Factorization (DAM3F), by integrating collaborative user-group information and user similarity matrix. Specifically, Maximum Margin Matrix Factorization (MMMF) is employed for the collaborative recommendation, while the user similarity matrix obtained from the user uploaded images and annotated tags is used as an complementary part to handle the cold start problem and to improve the performance of MMMF. The experiments conducted on our crawled dataset with 2196 users, 985 groups and 334467 images from Flickr demonstrate the effectiveness of the proposed approach.</abstract>
	</paper>
	<paper>
		<ID>277</ID>
		<title>A Relevance Weighted Ensemble Model for Anomaly Detection in Switching Data Streams</title>
		<authors>Mahsa Salehi (University of Melbourne),Christopher Leckie (University of Melbourne),Masud Moshtaghi (Monash University),Tharshan Vaithianathan (University of Melbourne)</authors>
		<abstract>Anomaly detection in data streams plays a vital role in on-line data mining applications. A major challenge for anomaly detection is the dynamically changing nature of many monitoring environments. This causes a problem for traditional anomaly detection techniques in data streams, which assume a relatively static monitoring environment. In an environment that is intermittently changing (known as switching data streams), static approaches can yield a high error rate in terms of false positives. To cope with dynamic environments, we require an approach that can learn from the history of normal behaviour in data streams, while accounting for the fact that not all time periods in the past are equally relevant. Consequently, we have proposed a relevance-weighted ensemble model for learning normal behaviour, which forms the basis of our anomaly detection scheme. The advantage of this approach is that it can improve the accuracy of detection by using relevant history, while remaining computationally efficient. Our solution provides a novel contribution through the use of ensemble techniques for anomaly detection in switching data streams. Our empirical results on real and synthetic data streams show that we can achieve substantial improvements compared to a recent anomaly detection algorithm for data streams.</abstract>
	</paper>
	<paper>
		<ID>280</ID>
		<title>For User-driven Software Evolution: Requirements Elicitation Derived from Mining Online Reviews</title>
		<authors>Wei Jiang (Beihang University),Haibin Ruan (),Li Zhang (Beihang University),Philip Lew (Beihang University),Jing Jiang ()</authors>
		<abstract>Online reviews that manifest user feedback have become an available resource for eliciting requirements to design future releases. However, due to complex and diverse opinion expressions, it is challenging to utilize automated analysis for deriving constructive feedback from these reviews. What’s more, determining important changes in requirements based on user feedback is also challenging. To address these two problems, this paper proposes a systematic approach for transforming online reviews to evolutionary requirements. According to the characteristics of reviews, we first adapt opinion mining techniques to automatically extract opinion expressions about common software features. To provide meaningful feedback, we then present an optimized method of clustering opinion expressions in terms of a macro network topology. Based on this feedback, we finally combine user satisfaction analysis with the inherent economic attributes associated with the software’s revenue to determine evolutionary requirements. Experimental results show that our approach achieves good performance for obtaining constructive feedback even with large amounts of review data, and furthermore discovers the evolutionary requirements that tend to be ignored by developers from a technology perspective.</abstract>
	</paper>
	<paper>
		<ID>285</ID>
		<title>A Novel Framework to Improve siRNA Efficacy Prediction</title>
		<authors>Bui Thang (JAIST)</authors>
		<abstract>Short interfering RNA sequences (siRNAs) can knockdown target genes and thus have an immense impact on biology and pharmacy research. The key question of which siRNAs have high knockdown ability in siRNA research remains challenging as current known results are still far from expectation. This work aims to develop a generic framework to enhance siRNA knockdown efficacy prediction. The key idea is first to enrich siRNA sequences by incorporating them with rules found for de- signing effective siRNAs and representing them as transformed matrices, then to employ the bilinear tensor regression to do prediction on those matrices. Experiments show that the proposed method achieves results better than existing models in most cases.</abstract>
	</paper>
	<paper>
		<ID>290</ID>
		<title>Activity Recognition Using a Few Label Samples</title>
		<authors>Heidar Davoudi (NTU),Xiaoli Li (Institute for Infocomm Research),Minh Nhut Nguyen (Institute for Infocomm Research (I2R),),Shonali Krishnaswamy (Institute for Infocomm Research, Singapore)</authors>
		<abstract>Sensor-based human activity recognition aims to automatically identify human activities from a series of sensor observations, which is a crucial task for supporting wide range applications. Typically, given sufficient training examples for all activities (or activity classes), supervised learning techniques have been applied to build a classification model using sufficient training samples for differentiating various activities. However, it is often impractical to manually label large amounts of training data for each individual activities. As such, semi-supervised learning techniques sound promising alternatives as they have been designed to utilize a small training set L, enhanced by a large unlabeled set U. However, we observe that directly applying semi-supervised learning techniques may not produce accurate classification. In this paper, we have designed a novel dynamic temporal extension technique to ex- tend L into a bigger training set, and then build a final semi-supervised learning model for more accurate classification. Extensive experiments demonstrate that our proposed technique outperforms existing 7 state- of-the-art supervised learning and semi-supervised learning techniques.</abstract>
	</paper>
	<paper>
		<ID>294</ID>
		<title>Characterizing Temporal Anomalies in Evolving Networks</title>
		<authors>Ranga Suri (CAIR),Narasimha Murty (Indian Institute of Science),Athithan G ()</authors>
		<abstract>Many real world networks evolve over time indicating their dynamic nature to cope up with the changing real life scenarios. Detection of various categories of anomalies, also known as outliers, in graph representation of such network data is essential for discovering different irregular connectivity patterns with potential adverse effects such as intrusions into a computer network. Characterizing the behavior of such anomalies (outliers) during the evolution of the network over time is critical for their mitigation. In this context, a novel method for an effective characterization of network anomalies is proposed here by defining various categories of graph outliers depending on their temporal behavior noticeable across multiple instances of the network during its evolution. The efficacy of the proposed method is demonstrated through an experimental evaluation using various benchmark graph data sets.</abstract>
	</paper>
	<paper>
		<ID>295</ID>
		<title>Mining Correlation Patterns among Appliances in Smart Home Environment</title>
		<authors>Yi-Cheng Chen (Tamkang University),Chien-Chih Chen (National Chiao Tung University),Wen-Chih Peng (National Chiao Tung University, Taiwan),Wang-Chien Lee (Pennsylvania State University, USA)</authors>
		<abstract>Since the great advent of sensor technology, the usage data of appliances in a house can be logged and collected easily today. However, it is a challenge for the residents to visualize how these appliances are used. Thus, mining algorithms are much needed to discover appliance usage patterns. Most previous studies on usage pattern discovery are mainly focused on analyzing the patterns of single appliance rather than mining the usage correlation among appliances. In this paper, a novel algorithm, namely, Correlation Pattern Miner (CoPMiner), is developed to capture the usage patterns and correlations among appliances probabilistically. With several new optimization techniques, CoPMiner can reduce the search space effectively and efficiently. Furthermore, the proposed algorithm is applied on a real-world dataset to show the practicability of correlation pattern mining.</abstract>
	</paper>
	<paper>
		<ID>298</ID>
		<title>Overlapping Communities for Identifying Misbehavior in Network Communications</title>
		<authors>Farnaz Moradi (Chalmers University of Technol),Tomas Olovsson (Chalmers University of Technology),Philippas Tsigas (Chalmers University of Technology)</authors>
		<abstract>In this paper, we study the problem of identifying misbehaving network communications using community detection algorithms. Recently, it was shown that identifying the communications that do not respect community boundaries is a promising approach for network intrusion detection. However, it was also shown that traditional community detection algorithms are not suitable for this purpose.  In this paper, we propose a novel method for enhancing community detection algorithms, and show that contrary to previous work, they provide a good basis for network misbehavior detection. This enhancement extends disjoint communities identified by these algorithms with a layer of auxiliary communities, so that the boundary nodes can belong to several communities. Although non-misbehaving nodes can naturally be in more than one community, we show that the majority of misbehaving nodes belong to multiple overlapping communities, therefore overlapping community detection algorithms can also be deployed for intrusion detection. Finally, we present a framework for anomaly detection which uses community detection as its basis. The framework allows incorporation of application-specific filters to reduce the false positives induced by community detection algorithms. Our framework is validated using large email networks and flow graphs created from real network traffic.</abstract>
	</paper>
	<paper>
		<ID>301</ID>
		<title>Balanced Seed Selection for Budgeted Influence Maximization in Social Networks</title>
		<authors>Shuo Han (Institute of Computing Technology, Chinese Academy of Science),Fuzhen Zhuang (ICT),Qing He (Institute of Computing Technology, Chinese Academy of Science),Zhongzhi Shi (Institute of Computing Technology, Chinese Academy of Science)</authors>
		<abstract>Given a budget and a network where different nodes have different costs to be selected, the budgeted influence maximization is to select seeds on budget so that the number of final influenced nodes can be maximized. In this paper, we propose three strategies to solve this problem. First, Billboard strategy chooses the most influential nodes as the seeds. Second, Handbill strategy chooses the most cost-effective nodes as the seeds. Finally, Combination strategy chooses the ``best'' seeds from two ``better'' seed sets obtained from the former two strategies. Experiments show that Billboard strategy and Handbill strategy can obtain good solution efficiently. Combination strategy is the best algorithm or matches the best algorithm in terms of both accuracy and efficiency, and it is more balanced than the state-of-the-art algorithms.</abstract>
	</paper>
	<paper>
		<ID>305</ID>
		<title>Beyond Poisson: Modeling Inter-Arrival Time of Requests in a Datacenter</title>
		<authors>Da-Cheng Juan (CMU),Lei Li (UC Berkeley),Huan-Kai Peng (CMU),Diana Marculescu (CMU),Christos Faloutsos (CMU)</authors>
		<abstract>How frequently are computer jobs submitted to an industrial-scale datacenter? We investigate the trace that contains job requests and execution collected in one of large-scale industrial datacenters, which spans near half of a Terabyte. In this paper, we discover and explain two surprising patterns with respect to the inter-arrival time (IAT) of job requests: (a) multiple periodicities and (b) multi-level bundling effects. Specifically, we propose a novel generative process, Hierarchical Bundling Model (HiBM), for modeling the data. HiBM is able to mimic multiple components in the distribution of IAT, and to simulate job requests with the same statistical properties as in the real data. We also provide a systematic approach to estimate the parameters of HiBM.</abstract>
	</paper>
	<paper>
		<ID>310</ID>
		<title>Mining GPS Data for Trajectory Recommendation</title>
		<authors>Peifeng Yin (Pennsylvania State University),Mao Ye (Pintrest),Wang-Chien Lee (Pennsylvania State University, USA),Zhenhui Li (Pennsylvania State University, USA)</authors>
		<abstract>The wide use of GPS sensors in smart phones encourages people to record their personal trajectories and share them with others in the Internet. A recommendation service is needed to help people process the large quantity of trajectories and select potentially interesting ones. The GPS trace data is a new format of information and few works focus on building user preference profiles on it. In this work we proposed a trajectory recommendation framework and developed three recommendation methods, namely, Activity-Based Recommendation (ABR), GPS-Based Recommendation (GBR) and Hybrid Recommendation. The ABR recommends trajectories purely relying on activity tags. For GBR, we proposed a generative model to construct user profiles based on GPS traces. The Hybrid recommendation combines the ABR and GBR. We finally conducted extensive experiments to evaluate these proposed solutions and it turned out the hybrid solution displays the best performance.</abstract>
	</paper>
	<paper>
		<ID>314</ID>
		<title>Two sides of a coin: Separating Personal Communication and Public Dissemination Accounts in Twitter</title>
		<authors>Peifeng Yin (Pennsylvania State University),Nilam Ram (Pennsylvania State University),Wang-Chien Lee (Pennsylvania State University, USA),Conrad Tucker (Pennsylvania State University),Shashank Khandelwal (Pennsylvania State University),Marcel Salathe (Pennsylvania State University)</authors>
		<abstract>There are millions of accounts in Twitter. In this paper, we categorize twitter accounts into two types, namely \emph{Personal Communication Account (PCA)} and \emph{Public Dissemination Account (PDA)}. PCAs are accounts relating to individuals and are used to express an individual's thoughts and feelings. PDAs, on the other hand, refer to accounts owned by non-individuals such as companies, governments, etc. Generally, Tweets in PDA (i) disseminate a specific type of information (e.g., job openings, shopping deals, car accidents) rather than sharing an individual's personal life; and (ii) may be produced by non-human entities (e.g., bots). We aim to develop techniques for identifying PDAs so as to (i) facilitate social scientists to reduce ``noise'' for their study in human behaviors, and (ii) to index them for potential recommendation to users looking for specific types of information. Through analysis, we find these two types of accounts follow different temporal, spatial and textual patterns. Accordingly we develop probabilistic models based on these features to identify PDAs. We also conduct a series of experiments to evaluate those algorithms for cleaning the Twitter data stream.</abstract>
	</paper>
	<paper>
		<ID>315</ID>
		<title>Fault-tolerant Concept Detection in Information Networks</title>
		<authors>Tobias Koetter (Carnegie Mellon University),Stephan Günnemann (Carnegie Mellon University),Christos Faloutsos (CMU),Michael Berthold (University of Konstanz, Germany)</authors>
		<abstract>Given information about medical drugs and their properties, how can we automatically discover that Aspirin has blood-thinning properties, and thus prevents heart attacks? Expressed in more general terms, if we have a large information network that integrates data from heterogeneous data sources, how can we extract semantic information that provides a better understanding of the integrated data and also helps us to identify missing links? We propose to extract concepts that describe groups of objects and their common properties from the integrated data. The discovered concepts provide semantic information as well as an abstract view on the integrated data and thus improve the understanding of complex systems. Our proposed method has the following desirable properties: (a) it is parameter-free and therefore requires no user-defined parameters (b) it is fault-tolerant, allowing for the detection of missing links and (c) it is scalable, being linear on the input size. We demonstrate the effectiveness and scalability of the proposed method on real, publicly available graphs.</abstract>
	</paper>
	<paper>
		<ID>334</ID>
		<title>A Framework for Large-Scale Train Trip Record Analysis and Its Application to Passengers' Flow Prediction after Train Accidents</title>
		<authors>Daisaku Yokoyama (The University of Tokyo),Masahiko Itoh (The University of Tokyo),Masashi Toyoda (The University of Tokyo),Yoshimitsu Tomita (Tokyo Metro Co., Ltd.),Satoshi Kawamura (Tokyo Metro Co., Ltd.),Masaru Kitsuregawa (Institute of Industrial Science, the University of Tokyo)</authors>
		<abstract>We have constructed a framework for analyzing passenger behaviors  in public transportation systems  as understanding these variables is a key to improving the efficiency of  public transportation.  It uses a large-scale dataset of trip records created from smart card data  to estimate passenger flows in a complex metro network.  Its interactive flow visualization function enables  various unusual phenomena to be observed.  We propose a predictive model of passenger behavior after a train accident.   Evaluation showed that it can accurately predict passenger flows after  a major train accident.  The proposed framework is the first step towards  real-time observation and prediction for public transportation systems. </abstract>
	</paper>
	<paper>
		<ID>335</ID>
		<title>Finding Well-Clusterable Subspaces for High Dimensional Data A Numerical One-Dimension Approach</title>
		<authors>Chuanren Liu (Rutgers Business School),Tianming Hu (),Yong Ge (UNCC),Hui Xiong (Rutgers University, USA)</authors>
		<abstract>High dimensionality poses two challenges for clustering algorithms: features may be noisy and data may be sparse. To address these challenges, subspace clustering seeks to project the data onto simple yet informative subspaces. The projection process should be fast and the projected subspaces should be well-clusterable. In this paper, we describe a numerical one-dimensional subspace approach for high dimensional data. First, we show that the numerical one-dimensional subspaces can be constructed efficiently by controlling the correlation structure. Next, we propose two strategies to aggregate the representatives from each numerical one-dimensional subspace into the final projected space, where the clustering problem becomes tractable. Finally, the experiments on real-world document data sets demonstrate that, compared to competing methods, our approach can find more clusterable subspaces which align better with the true class labels.</abstract>
	</paper>
	<paper>
		<ID>343</ID>
		<title>A Graph Matching Method for Historical Census Household Linkage</title>
		<authors>Zhichun Fu (ANU),Peter Christen (The Australian National University, Australia),Jun Zhou (Griffith University)</authors>
		<abstract>Linking historical census data across time is a challenging task due to various reasons, including data quality, limited individual information, and changes to households over time. Although most census data linking methods link records that correspond to individual household members, recent advances show that linking households as a whole provide more accurate results and less multiple household links. In this paper, we introduce a graph-based method to link households, which takes the structural relationship between household members into consideration. Based on individual record linking results, our method builds a graph for each household, so that the matches are determined by both attribute-level and record-relationship similarity. Our experimental results on both synthetic and real historical census data have validated the effectiveness of this method. The proposed method achieves an F-measure of 0.937 on data extracted from real UK census datasets, outperforming all alternative methods being compared.</abstract>
	</paper>
	<paper>
		<ID>344</ID>
		<title>Efficiently and Fast Learning a Fine-grained Stochastic Blockmodel from Large Networks</title>
		<authors>Xuehua Zhao (College of Computer Science and Technology, Jilin University, Changchun, China),Bo Yang (Jilin University, China),Hechang Chen (College of Computer Science and Technology, Jilin University, Changchun, China)</authors>
		<abstract>Stochastic blockmodel (SBM) has recently come into the spotlight in the domains of social network analysis and statistical machine learning, as it enables us to decompose and then analyze an exploratory network without knowing any priori information about its intrinsic structure. However, the prohibitive computational cost limits SBM learning algorithm with the capability of model selection to small network with hundreds of nodes. This paper presents a fine-gained SBM and its fast learning algorithm, named FSL, which ingeniously combines the component-wise EM (CEM) algorithm and minimum message length (MML) together to achieve the parallel learning of parameter estimation and model evaluation. The FSL effectively and efficiently reduces the time complexity of the learning algorithm, and scales to network with thousands of nodes.</abstract>
	</paper>
	<paper>
		<ID>347</ID>
		<title>Inducing controlled error over variable length ranked lists</title>
		<authors>Laurence Park (University of Western Sydney),Glenn Stone (University of Western Sydney)</authors>
		<abstract>When examining the robustness of systems that take ranked lists as input, we can induce noise, measured in terms of Kendall's tau rank correlation, by applying a set number of random adjacent transpositions.  The set number of random transpositions ensures that any ranked lists, induced with this noise, has a specific expected Kendall's tau. However, if we have ranked lists of varying length, it is not clear how many random transpositions we must apply to each list to ensure that we obtain a consistent expected Kendall's tau across the collection. In this article we investigate how to compute the number of random adjacent transpositions required to obtain an expected Kendall's tau for a given list length, and find that it is infeasible to compute for lists of length more than 9. We also investigate an alternate and more efficient method of inducing noise in ranked lists called Gaussian Perturbation. We show that using this method, we can compute the parameters required to induce a consistent level of noise for lists of length $10^7$ in just over six minutes. We also provide an approximate solution to provide results in less than $10^{-5}$ seconds.</abstract>
	</paper>
	<paper>
		<ID>348</ID>
		<title>Patent Evaluation Based on Technological Trajectory Revealed in Relevant Prior Patents</title>
		<authors>Sooyoung Oh (Penn State University),Zhen Lei (Penn State University),Wang-Chien Lee (Pennsylvania State University, USA),John Yen (Penn State University)</authors>
		<abstract>It is a challenging task for firms to assess the importance of a patent and identify valuable patents as early as possible. Counting the number of citations received is a widely used method to assess the value of a patent. However, recently granted patents have few citations received, which makes the use of citation counts infeasible. In this paper, we propose a novel idea to evaluate the value of new or recently granted patents using recommended relevant prior patents. Our approach is to exploit trends in temporal patterns of relevant prior patents, which are highly related to patent values. We evaluate the proposed approach using two patent value evaluation tasks with a large-scale collection of U.S. patents. Experimental results show that the models created based on our idea significantly enhance those using the baseline features or patent backward citations.</abstract>
	</paper>
	<paper>
		<ID>354</ID>
		<title>Topic Modeling using Collapsed Typed Dependency Relations</title>
		<authors>Elnaz Delpisheh (York University),Aijun An (Department of Computer Science and Engineering,York University, Canada)</authors>
		<abstract>Topic modeling is a powerful tool to uncover hidden thematic structures of documents. Many conventional topic models represent documents as a bag-of-words, where the important linguistic structures of documents are neglected. In this paper, we propose a novel topic model that enriches text documents with collapsed typed dependency relations to effectively acquire syntactic and semantic dependencies between consecutive and nonconsecutive words of text documents. In addition, we propose to enforce coherent topic assignments for conceptually similar words by generalizing words with their synonyms. Our experimental studies show that the proposed model and strategy outperform the original LDA model and the Bigram Topic Model in terms of perplexity; and our performance is comparable to other models in terms of stability, coherence, and accuracy.</abstract>
	</paper>
	<paper>
		<ID>357</ID>
		<title>Self-Training Temporal Dynamic Collaborative Filtering</title>
		<authors>Cheng Luo (University of New South Wales),Xiongcai Cai (UNSW),Nipa Chowdhury (UNSW)</authors>
		<abstract>Recommender systems (RS) based on collaborative filtering (CF) is traditionally incapable of modeling the often non-linear and non Gaussian tendency of user taste and product attractiveness leading to unsatisfied  performance. Particle filtering, as a dynamic modeling method, enables tracking of such tendency. However, data are often extremely sparse in real-world RS under temporal context, resulting in less reliable tracking.  Approaches to such problem seek additional information or impute all or most missing data to reduce sparsity, which then causes scalability problems for particle filtering. In this paper, we develop a novel semi-supervised method to simultaneously solve the problems of data sparsity and scalability in a particle filtering based  dynamic recommender system. Specifically, it exploits the self-training principle to dynamically construct observations based on current prediction distributions. The proposed method is evaluated on two public benchmark datasets, showing significant improvement over a variety of existing methods for top-k recommendation in both accuracy and scalability.</abstract>
	</paper>
	<paper>
		<ID>360</ID>
		<title>ReadBehavior: Reading Probabilities Modeling of Tweets via the Users' Retweeting Behaviors</title>
		<authors>Jianguang Du (BIT),Dandan Song (BIT),Lejian Liao (BIT),Xin Li (BIT),Li Liu (BIT),Guoqiang Li (),Guanguo Gao (BIT),Guiying Wu (BIT)</authors>
		<abstract>Along with twitter's tremendous growth, studying users' behaviors, such as retweeting behavior, have become an interesting research issue. In literature, researchers usually assumed that the twitter user could catch up with all the tweets posted by his/her friends. This is untrue most of the time. Intuitively, modeling the reading probability of each tweet is of practical importance in various applications, such as social influence analysis. In this paper, we propose a ReadBehavior model to measure the probability that a user reads a specific tweet. The model is based on the user's retweeting behaviors and the correlation between the tweets' posting time and retweeting time. To illustrate the effectiveness of our proposed model, we develop a PageRank-like algorithm to find influential users. The experimental results show that the algorithm based on ReadBehavior outperforms other related algorithms, which indicates the effectiveness of the proposed model.</abstract>
	</paper>
	<paper>
		<ID>364</ID>
		<title>Constrained-hLDA for Topic Discovery in Chinese Microblogs</title>
		<authors>Wei Wang (Tsinghua University),Hua Xu (Tsinghua University),Weiwei Yang (Tsinghua University),Xiaoqiu Huang (Tsinghua University)</authors>
		<abstract> Since microblog service became information provider on web scale, research on microblog has begun to focus more on its content mining. Most research on microblog context is often based on topic models, such as: Latent Dirichlet Allocation(LDA) and its variations. However,there are some challenges in previous research. On one hand, the number of topics is fixed as a priori, but in real world, it is input by the users. On the other hand, it ignores the hierarchical information of topics and cannot grow structurally as more data are observed. In this paper, we propose a semi-supervised hierarchical topic model, which aims to explore more reasonable topics in the data space by incorporating some constraints into the modeling process that are extracted automatically. The new method is denoted as constrained hierarchical Latent Dirichlet Allocation (constrained-hLDA). We conduct experiments on Sina microblog, and evaluate the performance in terms of clustering and empirical likelihood. The experimental results show that constrained-hLDA has a significant improvement on the interpretability, and its predictive ability is also better than that of hLDA.</abstract>
	</paper>
	<paper>
		<ID>369</ID>
		<title>HOSLIM: Higher-Order Sparse LInear Method for Top-N Recommender Systems</title>
		<authors>Evangelia Christakopoulou (University of Minnesota),George Karypis (University of Minnesota, USA)</authors>
		<abstract>Current top-N recommendation methods compute the recommendations by taking into account only relations between pairs of items, thus leading to potential unused information when higher-order relations between the items exist. Past attempts to incorporate the higher-order information were done in the context of neighborhood-based methods. However, in many datasets, they did not lead to significant improvements in the recommendation quality. We developed a top-N recommendation method that revisits the issue of higher-order relations, in the context of the model-based Sparse LInear Method (SLIM). The approach followed (Higher-Order Sparse LInear Method, or HOSLIM) learns two sparse aggregation coefficient matrices S and S' that capture the item-item and itemset-item similarities, respectively. Matrix S' allows HOSLIM to capture higher-order relations, whose complexity is determined by the length of the itemset. Following the spirit of SLIM, matrices S and S' are estimated using an elastic net formulation, which promotes model sparsity. We conducted extensive experiments which show that higher-order interactions exist in real datasets and when incorporated in the HOSLIM framework, the recommendations made are improved. The experimental results show that the greater the presence of higher-order relations, the more substantial the improvement in recommendation quality is, over the best existing methods. In addition, our experiments show that the performance of HOSLIM remains good when we select S' such that its number of nonzeros is comparable to S, which reduces the time required to compute the recommendations.</abstract>
	</paper>
	<paper>
		<ID>378</ID>
		<title>Latent Features Based Prediction on New Users’ Tastes</title>
		<authors>Ming-Chu Chen (National Cheng Kung University),Hung-Yu Kao (National Cheng Kung University, Taiwan)</authors>
		<abstract>Recommendation systems have become popular in recent years. A key challenge in such systems is how to effectively characterize new users’ tastes — an issue that is generally known as the cold-start problem. New users judge the system by the ability to immediately provide them with what they consider interesting. A general method for solving the cold-start problem is to elicit information about new users by having them provide answers to interview questions. In this paper, we present Matrix Factorization K-Means (MFK), a novel method to solve the problem of interview question construction. MFK first learns the latent features of the user and the item through observed rating data and then determines the best interview questions based on the clusters of latent features. We can determine similar groups of users after obtaining the re-sponses to the interview questions. Such recommendation systems can indicate new users’ tastes according to their responses to the interview questions. In our experiments, we evaluate our methods using a public dataset for recommenda-tions. The results show that our method leads to better performance than other baselines.</abstract>
	</paper>
	<paper>
		<ID>387</ID>
		<title>Unsupervised Analysis of Web Page Semantic Structures by Hierarchical Bayesian Modeling</title>
		<authors>Minoru Yoshida (University of Tokushima),Kazuyuki Matsumoto (),Kenji Kita (),Hiroshi Nakagawa (University of Tokyo, Japan)</authors>
		<abstract>We propose a Bayesian probabilistic modeling of the semantic structures of HTML documents. We assume that HTML documents have logically hierarchical structures  and model them as links between blocks. These links or dependency structures are estimated by sampling methods.  We use hierarchical Bayesian modeling where each block is given labels such as &quot;heading&quot; or &quot;contents&quot;, and words and layout features (i.e., symbols and HTML tags) are generated simultaneously, based on these labels.</abstract>
	</paper>
	<paper>
		<ID>388</ID>
		<title>Collective Matrix Factorization of Predictors, Neighborhood and Targets for Semi-Supervised Classification</title>
		<authors>Lucas Drumond (University of Hildesheim),Lars Schmidt-Thieme (University of Hildesheim),Christoph Freudenthaler (),Artus Krohn-Grimberghe ()</authors>
		<abstract>Due to the small size of available labeled data for semi-supervised learning, approaches to this problem make strong assumptions about the data, performing well only when such assumptions hold true. However, a lot of effort may have to be spent in understanding the data so that the most suitable model can be applied. This process can be as critical as gathering labeled data. One way to overcome this hindrance is to control the contribution of different assumptions to the model, rendering it capable of performing reasonably in a wide range of applications. In this paper we propose a collective matrix factorization model that simultaneously decomposes the predictor, neighborhood and target matrices (PNT-CMF) to achieve semi-supervised classification. By controlling how strongly the model relies on different assumptions, PNT-CMF is able to perform well on a wider variety of datasets. Experiments on synthetic and real world datasets show that, while state-of-the-art models (TSVM and LapSVM) excel on datasets that match their characteristics and have a performance drop on the others, our approach  outperforms them being consistently competitive in different situations.</abstract>
	</paper>
	<paper>
		<ID>395</ID>
		<title>Programmatic buying bidding strategies with win rate and winning price estimation in real time mobile advertising </title>
		<authors>Xiang Li (Drawbridge Inc),Devin Guan (Drawbridge inc)</authors>
		<abstract>A major trend in mobile advertising is the emergence of real time bidding (RTB) based marketplaces on the supply side and the corresponding programmatic impression buying on the demand side. In order to acquire the most relevant audience impression at the lowest cost, a demand side player has to accurately estimate the win rate and winning price in the auction, and incorporate that knowledge in its bid. In this paper, we describe our battle-proven techniques of predicting win rate and winning price in RTB, and the corresponding bidding strategies built on top of those predictions. We also reveal the close relationship between the win rate and winning price estimation, and demonstrate how to solve the two problems together. All of our estimation methods are developed with distributed framework and have been applied to billion order numbers of data in real business operation. </abstract>
	</paper>
	<paper>
		<ID>401</ID>
		<title>Document Clustering with an Augmented Nonnegative Matrix Factorization Model</title>
		<authors>Zunyan Xiong (Drexel University),Yizhou Zang (),Xingpeng Jiang (),Xiaohua Hu ()</authors>
		<abstract>In this paper, we propose an augmented NMF model to investigate the latent features of documents. The augmented NMF model incorporates the original nonnegative matrix factorization and the local invariance assumption on the document clustering. In our experiment, first we compare our model to baseline algorithms with several benchmark datasets. Then the effectiveness of the proposed model is evaluated using datasets from CiteULike. The clustering results are compared against the subject categories from Web of Science for the CiteULike dataset. Experiments of clustering on both benchmark data sets and CiteULike datasets outperforms many state of the art clustering methods.</abstract>
	</paper>
</paperlist>